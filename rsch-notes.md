Research notes
==============

Aaron Tran
Summer 2014

This is a running log of thoughts, actions -- a lazy man's lab notebook.

Table of contents?
==================

* Week 1 - DS9 region selection and first look at profiles
* Week 2 - CIAO/HEASOFT setup, specextract to check thermal emission in regions
* Week 3 - iMac setup, PyXspec script, start profile fitting
* Week 4 - profile fitting expts, new energy bands
* Week 5 - fix profile fit errors, FWHM and `m_E` calculation, Sean's code
* Week 6 - TBD



(Week 1) Monday, 2014 June 2
============================

* Morning NASA orientation
* Meeting with Rob Petre until about 1-2p?
* Not much work done (I can't even remember what I did...)
* CRESST orientation


Tuesday, 2014 June 3
====================

Summary
-------

* Installed ds9 to ~/bin. In `.bash_profile`, add: `export PATH=~/bin:$PATH`
* Messed around on ds9, went through user's manual.  Played with ds9 commands.

Agenda, useful items?
---------------------

[ds9 command line options](http://ds9.si.edu/ref/command.html) will be useful
Looks like we need pyds9, or XPA, for consecutive commands...

Need to cover, for my own learning
1. basic radiative processes (thermal, nonthermal emission)
2. supernova physics (temperatures, radiation/spectra during evolution)
3. physics of Tycho -- interpretation of the fluff.  ISM gradient.
4. Ressler et al. (in press, ApJ)

5. X-ray telescopes.  Resolution, operation, limitations

whether in some kind of lab notebook, LaTeX file, or whatever

Meanwhile: construct and save shape files of the regions for which to extract
spectra.
1. Make a preliminary region, just eyeballing it / doing it by hand
2. Read Ressler.  Look at any similar papers where people look at filament
   spectra
3. Figure out if there's any more systematic way.  How far beyond the shock, or
   interior of the shock, should the region extend?  Physics motivating this.

Main Tycho (SN 1572) data
-------------------------

All files have been generated by Brian, sent to Rob.
He's already done the processing work with CIAO etc...

Three data files are:

* `0.7-1kev_mosaic.fits`
* `1-2kev_mosaic.fits`
* `2-7kev_mosaic.fits`

Resolution: 1 arcsecond (downsampled, Chandra has 0.5 arcsec resolution).
To verify this, poking around in DS9 (looking at pixel coords):
* RA:  0.98 arcsec = 0.150 seconds * (360 deg/24 hr) * cos(64.167 deg)
* DEC: ~1.0 arcsec

We also have `2009_3to7kev.fits`, resolution is 0.5 arcsec (very few counts)

Meddling with ds9
-----------------

Generating an RGB image using these images may be useful to help,
e.g., identify thermal contamination using all bands.

Scaling limits: goal is to simply reject background.
Method: look @ heatmap -- SNR should be ~pure white, background is colorful.
Mainly, we lose some information about high count pixels
(only O(10^1) pixels will thus saturate)

* 0.7-1 keV: 4e-8, 2.1e-6
* 1-2 keV:   4e-8, 2.42e-6
* 2-7 keV:   3e-8, 1.5e-6

Example "one-liner" for an RGB image (modified Jun 4):

    ds9 -rgb \
        -red 0.7-1kev_mosaic.fits \
            -scale limits 4e-8 2.1e-6 \
        -green 1-2kev_mosaic.fits \
            -scale limits 4e-8 2.42e-6 \
        -blue 2-7kev_mosaic.fits \
            -scale limits 3e-8 1.5e-6 \
        -rgb lock scale yes \
        -asinh

For a single file:

    ds9 2-7kev_mosaic.fits \
        -scale limits 4e-8 2.1e-6 -asinh -cmap Heat

Qualitatively:
* sqrt is useful to bring out thin/wispy filaments (bottom-left / SE corner)
* asinh, histogram eq. are useful for contrast, dramatic nice pictures.
  Can definitely see stripping, little wisps, esp. in 2-7 keV

sqrt makes low energy stuff slightly brighter, asinh makes high energy stuff
brighter.  In general, both serve to pull out low energy detail, and brighten
high energy stuff (closer to saturating).  Hist. eq. does this even more
extremely, it seems.

Radial profile selection with ds9
---------------------------------
Region specification:

    projection x1 y1 x2 y2 width

(x1, y1) and (x2, y2) specify coordinates of bounding box, I suppose

My next question is how do you specify a width?



Wednesday, 2014 June 4
======================

Summary
-------
* Began selecting regions for fits
* Met with Rob about next plans
* Laid out next steps (for processing fits)
* Found strange object inside Tycho

Selecting regions
-----------------

Setup command for generating projection regions:

    ds9 -rgb \
        -red 0.7-1kev_mosaic.fits \
            -scale limits 4e-8 2.1e-6 \
        -green 1-2kev_mosaic.fits \
            -scale limits 4e-8 2.42e-6 \
        -blue 2-7kev_mosaic.fits \
            -scale limits 3e-8 1.5e-6 \
        -rgb lock scale yes \
        -histequ

Note that order matters here -- lock the scale after setting limits in each
channel, so they will all have different limits.

Agenda for now
1. Get some rough guesses / shapes / regions to save, by eyeballing...
2. Figure out how to generate plots from those regions automatically.
3. Think about calculating ``radial distance''.  How do we get the center?
    a. Centroid of gamma-ray emission given by (Acciari et al., 2011).
       But, this is offset by 0.04 deg. = 2.4 arcminutes
       Compare the remnant diameter ~0.14 deg. = 8.4 arcminutes
       Eyeballing from mosaic fits file, center is abt:
       (RA, dec) = (00:25:17, +64:08:00) (+/- 3 sec RA, +/- 30 arcsec dec)

Projection drawing
------------------
Just initial guesses, to save/play with.

See notes file in data/

Sanity check: if I generate a region and save/reload, will it have the right
rotation? How is this saved with only two points?
Answer: if I save in ds9 format, it appears to store a "thickness" as well.
The "thickness" direction is determined by the ordering of the two points,
so the region's orientation is fully specified.
Yes: projection(x1,y1,x2,y2,width), width is "thickness", great.

When thinking about region sizes/counts:
* SN 1006 has diameter 0.5 deg., vs. ~0.14 deg. for SN 1572
* But count rates are much higher for SN 1572

Pulsar-looking thingy!! (brief diversion)
-----------------------------------------
Whoa!

Thing that looks like Crab Pulsar, located at:
RA, dec = 00:25:00.1, 64:10:44 (hr, deg.).  
Most visible in power scaling, also sinh.

* Rest frequency is between 1-2 keV, assume 1.5 keV --> 3.63e17 Hz.
* Redshifted stuff, 0.7-1 keV, assume 0.85 keV --> 2.06e17 Hz.
* Blueshifted stuff, 2-7 keV.  Don't know this (too large range).

Red frequency shift is 1.57e17 Hz.
From Doppler formula we can get the redshift as:
`(3.63 - 1.57) = (c - v)/(c + v) * 3.63`.
Velocity projected along line of sight is ~0.28c... wow.

Flip to solve for frequency of blueshifted material:
`(3.63 + \Delta f) = (1+0.28)/(1-0.28) * 3.63`
Blue frequency shift is 2.8e17 Hz,
thus blueshifted stuff has freq. ~6.4e17 Hz --> 2.6 keV.

Coooooooooool. But I don't know how to find further information, yet.

[update: now I feel rather silly -- it's probably just ejecta]

Next steps in region processing
-------------------------------

Ask about what we should see after the shock?  Hard to see whether present, or
thermal emission, or what.

* Run around SNR in each band, to check for any spots I missed, and note
  previous regions that look contaminated (in each band).
* Check each region individually for (1) clean in all bands, (2) long enough in
  front and back for fitting.
* Sort the filaments -- get the obviously good ones, then figure
  out how to make use of the blah and bad ones.  Which ones will we use?
* Background subtraction (compare local vs. global background).  I see two ways
  to approach this part.
  1. For each region, have enough extending outwards to estimate immediately
     nearby background.  Subtract mean from each spectrum (in each band
     separately, of course...)
  2. For entire image, we could get a thorough background spectrum (mask the
     SNR, apply a threshold and/or remove point sources [prefer latter to avoid
     losing information]).  Because background spectrum should have frequency
     dependence, this may be important when we generate spectra (checking for
     contamination/other effects).  But, binning in energy integrates over the
     frequency dependence.  So profiles just need a constant shift (?).
* Generating spectra and checking for contamination

2nd order stuff (nice but less important)
* Optimization
* Calculate *expected* curvature based on width of regions
  (idea, could quantify how wide these may be. But, multiple filaments likely
  to be a larger confounding effect)
 

More reproducible / automated profile region selection
------------------------------------------------------

Idea: try testing projections for minimum peak width, e.g. using pyds9.
    or, find when peak height is maximized

Supply initial guess regions, then rotate them about their centers (?) until
the filament peak width is minimized.  You should generate the projections in a
consistent way (just for ease of use/manipulation), e.g. starting from outside
and moving in.

(remember that we get THREE projection plots out, one for each band...)



Thursday, 2014 June 5
=====================

Summary
-------
* Finished selecting regions, color-coded by quality.
* Installed CIAO 4.6 on my computer (omitted HRC background event files)
* Installed ftools, XANADU (incl. XSPEC), XSTAR (HEASOFT 6.15.1)
  from pre-compiled binary
* Installed pyds9, Python interface to ds9 via XPA
* Created script to extract and plot profiles from ds9, using pyds9 interface

ciao4.6, ds9, heasoft-6.15.1 are all installed to `~/bin/`.
For heasoft, I had to use `./configure PERL=/usr/bin/perl`
to prevent Perl mismatch.

Note for background removal -- the black region outside the SNR is absolutely
not uniform -- there is a trend of decreasing counts towards the edge of the
image.

Agenda review
-------------

1. Re-do/tweak regions (wait for higher res images from Brian?)
    * Manual tweaking, see what Rob/Brian say
    * Possible optimization w/ pyds9
    * Check curvature?
2. Background subtraction (wait for discussion / how-to)

So now I want to generate plots of the counts (for first pass
review/discussion), and also start reading up and learning abt supernova
physics anyways (prepare for next stages).

Meanwhile I am installing the various software packages.

Extracting profile parameters using ds9's projection tool
---------------------------------------------------------

Whenever I change the current frame in an rgb image, all the projection plots
are automatically regenerated.  This was very annoying at first, but now I
can exploit this to get the plot data -- as I could not find a way to run the
analysis commands via pyds9/xpa!

:)

Please see iPython notebook in `data/`

TODO for FRIDAY

Improve plot quality (set .matplotlibrc or whatever)
Sort plots into good/bad/whatever


Friday, 2014 June 14
====================

Summary
-------
* Set up boilerplate plotting functionality (improve matplotlib defaults)
* Sent email to Rob/Brian with regions, plots, notes
* Started reviewing Jackson on synchrotron radiation (ch. 14)

pyds9 version of set-up code
----------------------------
Here we go...

    import ds9
    d = ds9.ds9()
    d.set('rgb')
    d.set('rgb red')
    d.set('file 0.7-1kev_mosaic.fits')
    d.set('scale limits 4e-8 2.1e-6')
    d.set('rgb green')
    d.set('file 1-2kev_mosaic.fits')
    d.set('scale limits 4e-8 2.42e-6')
    d.set('rgb blue')
    d.set('file 2-7kev_mosaic.fits')
    d.set('scale limits 3e-8 1.5e-6')
    d.set('rgb lock scale yes')
    d.set('scale histequ');

Agenda for today
----------------
* Twiddle with profile plots/scripts and send regions/plots/notes to Rob/Brian
* Twiddle with CIAO's specextract, just playing now
* Call abt NASA computer access? / email?
* X-ray mtg + GSFC colloq on geodesy (that's probably ~2 hr of your day...)
* Self-study of SNR physics, read Ressler paper

Notes
-----
CIAO looks a little tricky / not so interactive, probably could use some
feedback from Rob/Brian first.  I think learning about SNRs is higher priority
now, so I can better use CIAO/XSPEC/etc later on.

Currently I am setting up some boilerplate plotting material:

1. ~/.matplotlib/matplotlibrc
2. my own `fplot` module for matplotlib. This just prints the settings in use,
   intended for iPython notebooks or similar.  Maybe I can add more utilities
   later.

Okay, not perfect, but looks passable for now.

Sent email to Rob/Brian with regions, annotated regions/labels on Tycho image,
plots of radial intensity profiles, pictures of strange pulsar-like object.



(Week 2) Monday, 2014 June 9
============================

Summary
-------
* Meeting with Brian to look at region picks
* Wrote script (`ds9proj2box.py`) to convert ds9 region files to CIAO
  region files (aggressively made it usable).

What's the agenda for today?  Do some self-study / reading until meeting with
Brian at 11am... then see what to do (start messing with CIAO?).

(some reading about synchrotron radiation / bremsstrahlung ensues)

This is kind of inefficient to be honest.  I guess this is probably low
priority, but I need to pick this up more efficiently...  Do some problems.
Get an intro level astrophysics textbook `w__w`.

Meeting with Brian
------------------
Regions -- just start with 10-12 best ones for now.  Make sure they're good in
all three bands (certify this).

Run `chandra_repro` on raw data
Run `specextract`

We only need 176 kilosec. (longest obs) to check spectra for contamination.
obsID is 10095, `package_1531_140609112030.tar`

Yes, we are using Hughes' 2009 (750 ks) observation.


Work now
--------
Check that the "good" regions are good in all three bands.
Obtain spectra for these regions (and check the funny object while you're at
it) using CIAO.

Now writing script to convert DS9 projections into boxes.

Wow that took way longer than it was supposed to.
1. too sleepy at work...
2. figured out...
    * I don't need great circle formulae (linear approx)
    * Stupid me, RA and dec don't map cleanly onto x-y
    * Rewrite to use physical coords (interface with ds9 to generate and get
      rid of intermediate files)

Some pythonic reminders: to work with files, use:

    with open(...) as f:
        for line in f:
            print line
        # or if writing
        for line in stuff_to_write:
            f.write(line)

Regex is great... but you need to keep in mind the tools in your arsenal, and
reach for the right ones.  I guess it will take time.

Remember to move things to scripts, when needed (i.e., if I have to use a
script more than 1x or 2x?).  Use sysargv.

CIAO wants files in physical coordinates
(see, e.g., [this thread](http://cxc.harvard.edu/ciao/threads/regions/index.html#formats))


Tuesday, 2014 June 10
=====================

Summary
-------
* Read CIAO threads on `chandra_repro`, `specextract`
* Reprocess longest single observation (~176 ks, ObsID 10095)
* Troubleshoot specextract with Brian, generate test spectra
* XSPEC tutorial with Brian

Okay, now that I've got the region file conversion working...
onto generating stuff with specextract

CIAO reprocessing
-----------------

Now running `chandra_repro verbose=5` (it seems like it will take a while) on
the 176 ks observation (obsID 10095).
Finished abt 1 hr, 4 minutes later (`acis_process_events` took ~50 minutes)

    WARNING: Observation-specific bad pixel file set for session use:
        /Users/aarontran/Documents/snr-research/data/chandra/
        10095/repro/acisf10095_repro_bpix1.fits

    Run 'punlearn ardlib' when analysis of this dataset
    completed.

    The data have been reprocessed.
    Start your analysis with the new products in
    /Users/aarontran/Documents/snr-research/data/chandra/10095/repro

Meanwhile I start reading about specextract.

CIAO specextract
----------------

To use a stack, input
`pset specextract infle="acisblah.fits[sky=@../thing.ciaoreg]"`
instead of using the `region(..)` syntax.
But, specextract also demands a stack of equal size for `bkgfile`.

On the flip side, it may be more sensible now to select backgrounds near the
radial profiles themselves, instead of using this mega-thing that will take
forever to run.

Sequence of specextract commands
--------------------------------

    punlearn specextract
    pset specextract \
        infile="acisf10095_repro_evt2.fits \
               [sky=region(../../../thing_tycho.ciaoreg)]"
    pset specextract outroot=extracttest/spec
    pset specextract \
        bkgfile="acisf10095_repro_evt2.fits
                [sky=region(../../../background.ciaoreg)]"
    pset specextract verbose=2

    # These are already set by default
    pset specextract weight=yes
    pset specextract weight_rmf=no
    pset specextract combine=no

    # Ancillary files: aps, mskfile, badpixfile
    # should be automatically found

    # Not set yet cuz I'm clueless
    # energy_wmap, grouptype, binspec, bkg_grouptype, bkg_binspec

    plist specextract
    specextract

What's this `mode=h` stuff, that shows up?  Some threads explaining how to use
`chandra_repro` and `specextract` have this additional flag, but I can't find
its documentation.  Maybe a legacy thing.

This does take a little time, even though just a small region... the background
region was very large, maybe that's a bad idea.
Started around 12:28-12:30pm, 
Stopped at 13:47pm -- this is taking really long.  Could be because I locked my
screen to go grab lunch meanwhile, if that messed it up
It was stuck on mkwarf (made it through sky2tdet after a lonnnnng time)

Try again at 13:58pm.  Stop at 14:24, it's still sitting on mkwarf

Background region
-----------------
There is a decrease in counts away from the SNR, I'm not sure if this is
physical or not (or if this should be accounted for by `chandra_repro`, which
it might not be here).

One thing I could do is to take two concentric annuli of the background, to see
if the spectrum changes as a function of radial distance.

New profiles with 0.5" binning
------------------------------
I.e., no binning
Just re-run script (should get scale limits again)
The new plots look good.

Talked to Brian
---------------
Some troubleshooting:

1. the region I'm extracting spectrum from has too many counts (2 orders of
   magnitude more than, e.g., along rims)
2. background region is way too big -- you want to stay nearby.  How to tell
   quality of background region?  Eyeball... at least hundreds, thousands of
   counts to get a decent spectrum.  We'll look in XSPEC and see how it goes.
3. Idea: just generate a few background circles around the rims, then assign
   each background region to several nearby profiles.
4. Brian can send files with just count numbers, instead of intensity units,
   so I can mess with them / play with them.
5. Download Funtools for DS9, there's a way to get it to load in the menus of
   DS9 by default.
6. Some stuff in CIAO can run in parallel, take advantage of multiple cores.
   Not sure about specextract... (from skimming the page)

Brian explained that the program is generating a response function... response
matrix function or whatever.  Captures the chip's spatial and frequency
response, but must be generated on the fly each time, it's a multiplicative
process.

ALSO, MEETING TOMORROW BEFORE COFFEE/COOKIES THING, PROBABLY AROUND 9AM OR SO
WAKE UP EARLY, SLEEP EARLY, SEND STUFF INTO JVGR EES ASAP...

Trying again, using `testspec.ciaoreg` and `testspec_bg.ciaoreg` (smaller, both
nearby, looking at thermal emission).  Let it run -- and it finishes within a
few minutes!  Very snappy.

Move on to working with XSPEC, stop by Brian's office if
I get it to work! (and he can get me started)

Meddling with spectra
---------------------

I have the following files from a single run of `specextract`:

* `spec.pi`
* `spec_grp.pi`
* `spec_bkg.pi`
* `spec.arf`
* `spec.rmf`
* `spec_bkg.arf`
* `spec_bkg.rmf`

So we have a source spectrum, a grouped source spectrum,
and a background spectrum (`.pi` files).
Then we have weighted response files, for background as well.

REMEMBER, when starting xspec stuff (`heainit`), start before starting CIAO if
you are running in the same session, due to conflicts with parameter files.

See meeting notes for Brian's XSPEC tutorial!


Wednesday June 11
=================

Summary
-------
* Generated "cutback" good regions and test spectra with specextract, XSPEC
  (this took a long time, ~50 minutes for 10 regions + backgrounds)
* Meeting with Rob and Brian -- looked at spectra, discussed subsequent fitting
* Cleaned up files, try to make log more readable in future

Quick list of to-dos
--------------------

Due to the JVGR paper (and time mismanagement yesterday night)
I started actual work today ~12pm, quite late.  So I will be staying
late today, and pounding away to learn Tcl, XSPEC.

For now, what do I need to prepare for the meeting?  I won't be able to throw
together scripts for everything, yet (which I can mention). We need to:

1. assess quality of good and okay region files (plots/profiles already
   generated) (done, but need to do same using spectra)
2. draw up new "good" regions without the background thermal stuff (done)
3. draw up new "okay" regions without the background thermal stuff
4. run `specextract` on the good regions (okay regions too if time)

Cutback regions + background regions made, and converted to CIAO regions
(remember to use script for projection-type regions).

Meeting with Brian and Rob
--------------------------

Showed the spectra for the good regions, nonthermal emission.

Feedback on regions and spectra:

* Region 4 (next to the orange tuft) is really contaminated, welp.  Not gonna
  work.  If that was the only region we had available, then maybe... could try
  to subtract off stuff in the back.  But no, too much trouble.
* Region 3 (wispy NE filament) has some line emission.  Twiddle with the box
  and try to make it better!
* Need to document all of this stuff -- explain what's going on, where we
  looked, what we tried and did.

Looked at some of the southern regions -- yup, contamination is a problem.  I
didn't have spectra for those yet though.

Another extension (different project): something they worked on with another
remnant was to look at the precursor.  Electrons could diffuse ahead of the
shock, give rise to a squished out rim.  Here we are seeing very sharp rim
edges, which constrains some of the physics of those rims.

Iterative sort of process now -- adjust the region, check the spectrum and see
if you can get the Si line to go away.  Rinse and repeat (and log what you're
doing).  Take good notes -- when I'm gone they have to be able to say, "We
checked x region and it looked bad/good for y reason".  So log the bad
regions, log all the region twiddling.

Next step -- fit the spectra to a power law and verify that they look good.

* Power law is a strictly empirical model of course, but simple.  Don't care
  about the actual parameters, as long as it fits it's okay.
* `srcut` is a fitting model in XSPEC -- you supply a radio flux (at 1 GHz)
  and radio spectral index, then fit for the cut-off energy
  (and the spectral index after the knee is determined???).
  So you only get like one or two free parameters.
  Rooted in the physics very nicely, but more hassle.  Especially as radio
  telescopes just don't have the necessary resolution.

Amusingness: apparently Nina is working on the pink fluff, idea is to try
getting the Doppler velocities and constructing a 3-D map.  So we're dividing
and conquering on these supernova remnants.  Nina arriving Monday, can help get
her started on DS9/CIAO/HEASOFT stuff (Rob will cc on email).

Computer is still a question mark, Rob/Brian came to take a look a bit after
the meeting.

So I was underprepared for that meeting, not as much to discuss/present
unfortunately.  Not as many questions going in.

Funtools install
----------------
Installed Funtools 1.4.4 to `~/bin/saord/`.
Made some productivity tweaks (set-up MacVim so I can use splits etc.)
Research notes organization ---------------------------

To better organize my thoughts/work, and reduce clutter in this log file.
(although granted I'm tired right now, I'm having a hard time keeping track of
what needs to be done for research)

1. Create file for code pipeline (list commands that need to be run).
   Will store 1. commands, 2. make evident where I need scripts
2. Create a running agenda

Currently brain-dead (~7pm), I'm going to get food, come back, nap, and maybe
try working through the night.

Looking at all the spectrum plots now:
Regions 1, 3, 5, 6, 8, 9, 10 all have a weak Si line
Regions 2, 7 look relatively clean
Region 4 is very contaminated!  (could try splitting)

Of these regions, 5, 10 look to be a bit noisier.  But not terribly so.
Next, cutback regions for the OKAY/BAD regions, then spectra.


Thursday 2014 June 12
=====================

Summary
-------
* Experimented with specextract pipeline, figured out how to manipulate files
  and headers.  Some fiddling with XSPEC, and XSPEC model fitting, as well.
* Set up new computer!  This took a little while...
* Updated/improved script for making profile plots, made 0.5 arcsec resolution
  plots for all regions (good/iffy/bad)
* Made new background regions, to cover all possible regions
* Formulate pipeline for region/background processing and improvement
* Draft code for specextract scripting


Specextract pipeline
--------------------

New game plan: run specextract on the profiles and backgrounds independently,
and then link them together after the fact.  No redundancy.
From one test: run `specextract` and generate spectra for 1) lone region,
2) lone background, 3) region + background correction; then manually create
4) lone region linked to background using CIAO's `dmhedit`.
The linked spectra and the files all looked good!

(for `dmhedit` commands, see the end of this
[thread](http://cxc.harvard.edu/ciao/threads/extended/index.html#stepbystep)

Useful tools: fv (gui to interact w/ fits files), fdump (dump to plaintext!).
And, remember to use `fhelp name_of_ftool`


Back to ds9 regions
-------------------
Need to look at good/iffy regions and assess amt of thermal contamination.
Then move forward with fitting (1. fit power law, 2. profile fitting)
Updated script for generating profile plots
Now scripting the spectrum generation


Background regions around SNR
-----------------------------

Considerations when selecting background regions:
* CCD chip boundaries!  Visible in RGB image, w/ log scaling
  (bars of anomolously increased counts, cutting across the SNR)
* Point sources, most often in red (0.7-1 keV) or blue (2-7 keV)
* Get as close to SNR as possible
* Try to keep background region sizes similar
* Background regions should be larger than profiles -- to account for much
  smaller number of counts
Generally, use log scaling when drawing boundaries to reveal point sources.

I picked a good number, looking at `profiles_all.reg`.  I may revise them
though.


iMac computer setup
-------------------

New iMac arrived in the afternoon! Spent some time downloading files / setting
up various customizations.  In general I am installing most astro software
to `~/bin/`.  This should be added to `$PATH` in `.bash_profile`.

1. Set Finder, Firefox/Chrome, Terminal preferences (using bash right now...)
2. Set System Preferences (remap Caps Lock key to Ctrl)
3. RC files -- the following ones were imported / set-up

    .bash_profile
    .screenrc
    .vimrc
    .vim/colors/vividchalk.vim
    .matplotlib/matplotlibrc  # UPDATE after 
    .xspec/Xspec.init  # Just need to change the help doc viewers

4. Software:
    * MacVim (update `.bash_profile` alias accordingly)
    * TextMate (enable shell support for `mate` in preferences)
    * XCode (+ command line tools in preferenes)
    * homebrew (compared to macports, doesn't need sudo?)
    * Anaconda (Python distribution with numpy/scipy/matplotlib/iPython/etc.)
    * MacTeX
    * XQuartz (X11 windowing system, needed for subsequent astro software)
    * ds9, pyds9, Funtools
    * CIAO, HEASOFT

I think that is everything necessary so far... we'll see what else comes up.

Friday 2014 June 13
===================

Summary
-------
* Reviewed "good" region selection, created new set of good regions
  (see notes in `data/notes-profiles.md`)
* Ran specextract on new good region selection (17 regions, ~45 min.)
* XSPEC fitting tutorial with Brian
* Mike Werner's Spitzer colloquium (lots of cute/neat science)
* Created script to link regions and background spectra

Meet with Brian today!

Spectra organization
--------------------
Writing script to link backgrounds with regions.
See `pipeline.md` for details.

    data/
    data/spectra/bkg
    data/spectra/good-1
    data/spectra/good-2


(Week 3) Monday 2014 June 16
============================

Summary
-------

* Linked spectra together (`spec_linkbg.py`, `spec_clearbg.py` working)
* Software setup w/Nina (derp derp)
* Drafted script to parse spectra and output plots with PyXspec
* Started reinstalling/troubleshooting HEASOFT install, to get
  PyXspec functionality.


Spectra manipulation
--------------------

Linked spectra in `data/spectra/good-2` to backgrounds in `data/spectra/bkg`
I accidentally messed up the order of arguments to `spec_linkbg.py`
So, I created and executed `spec_clearbg.py` to clean up the BACKFILE entries
for the files in `data/spectra/bkg`.

Fiddling around with XSPEC's commands `identify`, `setplot id`, looking at
spectral line output/information

PyXspec setup -- HEASOFT reinstall
----------------------------------

YES, BEAUTIFUL, THERE IS SUCH A THING AS `PyXSPEC`... makes life easier.
Only possible issues: no implementations of commands: hardcopy, identify.
But I think we'll be okay.

Issues: binary installation of HEASOFT doesn't have the necessary PyXspec
files.  And, there may be trouble finding development header files:

* python is in `/opt/local/.../2.7/bin/python2.7`
* Python.h is in `/opt/local/.../2.7/include/python2.7/Python.h`
* libpython2.7.dylib is in `/opt/local/.../2.7/lib/libpython2.7.dylib`

where `...` shortens `Library/Frameworks/Python.framework/Versions`.
(use `find /opt/local -name [libpython*, Python.h]` to locate)
It should work as it searches relative to the executable's location.
And the configure didn't fail or anything.  But if this is an issue, add
symlinks to the relevant files...


HEASOFT reinstall
-----------------

Reinstall HEASOFT 6.15.1 from source as follows:

    export PERL=/usr/bin/perl
    export FC=gfortran-mp-4.7
    ./configure --prefix=/Users/aarontran/bin/heasoft-6.15.1/

This required:
1. reinstall MacPorts gfortran w/ 32-bit compatibility
   `sudo port install gcc47 +universal` (this takes a while...)
2. Two issues with MacPorts install of Python: could not find library/header
   files (`Python.h`, `libpython2.7.dylib`), and is 64-bit only.  Solutions:
   1) use Apple's Python with `sudo port select python none`.
   2) reinstall Macports Python with `sudo port install python27 +universal`
3. While building/making resource-intensive packages, run:
   `sudo mdutil -a -i [off/on]` to toggle Spotlight indexing.

If using Apple Python, the following issues occur:
1. need to issue bash command `export VERSIONER_PYTHON_PREFER_32_BIT=yes`
   in order to use PyXspec
2. Apple Python doesn't have matplotlib/scipy/other packages set-up
3. Not the version of python used by ipython

If using Macports Python (reinstalled with +universal flag):
1. need to issue command `arch -i386 [i]python` to run PyXspec
2. matplotlib/numpy/scipy aren't 32-bit compatible

Dammit.

Conclusion: PyXspec scripts must be run as, essentially, standalone scripts.
Saved output from said scripts can be passed to other scripts, which use 64 bit
Python.  Not much better than Tcl scripting and I burned about 8 hours on this.

On the bright side, PyXspec is pretty convenient!


Tuesday 2014 June 17
====================

Summary
-------
* Finished HEASOFT reinstall (notes above, merged with yesterday)
* Reviewed "good-2" set of regions for quality

Back to region quality review/inspection.  I now have:
1. spectra with fit parameters and a chi-squared
2. profile plots
3. RGB image of Tycho
to help evaluate the quality of all the selected regions. So I walk through
all the data and determine where else to adjust regions / pare down test/bad
regions.


Wednesday 2014 June 18
======================

Summary
-------
* Started installing software on iMac (see install log there)
* Cleaned up `regions-good-2.reg` and made `regions-good-3`.  See
  `notes-regions.md` for information on region rejections / twiddling.
* Ran pipeline on `regions-good-3` -- first complete test of pipeline.


Region (`regions-good-3`) selection
-----------------------------------

move backgrounds farther away and see if things change....
Start profile fitting.

Compile the fit statistics for all the regions.
Set up the computer...


Thursday 2014 June 19
=====================

Summary
-------
* Fixed HEASOFT install on iMac, and matplotlib/iPython problems with libpng
* Generate `background-2` regions and link spectra (`good-3`)
* Some reading about synchrotron rim physics (Cassam-Chenai, 2007, etc.)
* Began profile fitting.  Tested a two-exponential model with middling results


Friday 2014 June 20
===================

Summary
-------
* More twiddling with profile fits
* Meeting with Rob, discussed profile fitting
* Twiddled profile fits and tidied profile fitting script


Profile fitting uncertainties
-----------------------------
After talking to Rob in the morning, I estimate the uncertainties as follows.
Go into the unbinned mosaics, look at background noise.  The numbers seem to
appear in roughly discrete units.  Estimate the smallest discrete unit (of
course there is slight variation), and take that to be one count.  Do this for
all three bands.

I use this to convert flux/intensity to counts in the profile fitting notebook.
The values are:

    0.7-1 keV: 8e-9 intensity units
    1-2 keV: 2.8e-9 intensity units
    2-7 keV: 5e-9 intensity units

I'm very perplexed by the 0.7-1 keV units (although, truthfully, it does seem
to be in line with the amount of noise/spread of signal).


Profile fitting functions
-------------------------

Start with a two-exponential model:

    h_{\mathrm{up}}(x) &= A_u \exp \left(\frac{x_0-x}{w_u}\right) + C_u \\
    h_{\mathrm{down}}(x) &= A_d \exp \left(\frac{x - x_0}{w_d}\right) + C_d

The upstream/downstream split occurs at `x=x_s`, and I use `x_s` as a fit
parameter instead of `A_d`.  (we can chose to remove either `A_d` or `A_u` from
the fit).  For sanity, the parameters are:

    xs, x0, Cu, Cd, wu, wd, Au, Ad

and only seven of these parameters are free, because we demand continuity.
Here I list some approaches/settings that I've used:

0. Single step fit for everything, with decent initial guesses.  I used
   original regions-good-3 data (i.e., no thermal upswing in the back).
   This is the data / fit I brough to show Rob in the morning:

1. Two-step fit.  Freeze the split location xs, and fit.  Then unfreeze xs and
   try another fit.  This seems to work pretty well.

2. Introduce data with thermal counts in the back (good-3-allback).
   Now, in addition to two-step fit: smooth data and find local minimum nearest
   to the synchrotron peak.  Use this to bound the fitting domain.

3. As above, but also fit background terms Cu, Cd on first fit attempt.
   Didn't make things too much better, but less blowup.

4. Let Au be a fitting parameter instead of Ad -- rationale was that, since we
   have more consistent upstream data, it should be easier to fit Au and solve
   for Ad.  Still freeze xs, Cu, Cd on first fit, allow all to vary in the
   second fit.

This didn't seem to do a lot (Au goes to zero, blows up, or nails it).

5. Add x0 to the list of frozen parameters (freeze: x0, xs, Cu, Cd) in first
   fit.  Again, let all go free in second fit.

THIS WORKS WELL!

6. Now remove Cu,Cd from first fit freeze.  So only freeze x0, xs.
   This is okay.  For reference, let me note the initial guesses here

    # Freeze: xs, x0
    xs_fr = x_of_max + 0.5  # Smoothing shifts peak slightly left
    x0_fr = xs_fr + 0.5  # xs left of x0 in good fit (empirically speaking)

    # Free parameters: wu, Au, wd
    Cu_g = np.mean(y_fit[-3:])  # The obvious guess
    Cd_g = np.mean(y_fit[:3]) / 2.  # Usually shoots under trough
    wu_g = 0.5  # Upstream width
    wd_g = 2.5  # Downstream width
    Au_g = np.amax(y_fit)/2.  # Upstream amplitude
    init_guess = [Cu_g, Cd_g, wu_g, wd_g, Au_g]

Now, I want to improve some of the rattier fits.  So far this procedure isn't
too reproducible / well-documented, I'm just playing it by ear here.

Pushing the frozen value of xs forward, helps improve red fits slightly.
Only a few red regions are going NaN on me now.

    # Freeze: xs, x0
    xs_fr = x_of_max + 1.5  # Smoothing shifts peak slightly left
    x0_fr = xs_fr + 0.5  # xs left of x0 in good fit (empirically speaking)

    # Free parameters: wu, Au, wd
    Cu_g = np.mean(y_fit[-3:])  # The obvious guess
    Cd_g = np.mean(y_fit[:3]) / 2.  # Usually shoots under trough
    wu_g = 0.5  # Upstream width
    wd_g = 2.5  # Downstream width
    Au_g = np.amax(y_fit)/3.  # Upstream amplitude
    init_guess = [Cu_g, Cd_g, wu_g, wd_g, Au_g]

I think we are hitting diminishing marginal returns.  I'm very uncomfortable
with the instability of the fits.  It's probably time to consider another
fitting procedure...


Sunday 2014 June 22
===================

Summary
-------
* Further fitting fiddling


Summary of work on profile fitting should probably be moved to its own log
file, soon.

Anyways, to continue....

1. Try a two exponential model, but add one more parameter -- change x0 to xu
   and xd.  Try letting both go free, first.

   Holy smokes that really sucked.  Okay, if I do this, the approach would have
   to be -- freeze split, fit both sides, get a chi2.  Step split location
   until I find a minimum in chi2 space.

2. Implement a stepping approach for the decoupled two exponential model.
   Ahh, but this is difficult because the continuity requirement
   still forces them to be linked.

   Anyways I try this -- step xs over a range of numbers, getting the best fit.
   Then, unfreeze xs and let it run free too -- but in practice this doesn't
   do anything, because we've already let it run free.

   It looks, honestly, terrible.
   In chi^2 space, it tracks out a parabola like shape.
   But on rare occasion, it will jump to a better trajectory
   and give a much better fit.

   But we don't have a systematic way to reach said trajectory!  Here's an
   example of a good fit from the better trajectory (the best one in this test)

    red fit (xs frozen): xs = 22.04, xu =  21.5, xd = -235.1,
    Cu = 0.3992, Cd = 1.598, wu = 0.981, wd = 1.492, Au = 8.589
    chi2 =  35.7, chi2red =  0.51

   It looks like the "coupled" 2-exponential model still does better, actually,
   with good initial guesses (chi2red = 0.50 instead).  And, it doesn't crash
   and burn on everything else.

So, let's give up on this decoupled model.  Adding another free parameter is
just making things worse.


(Week 4) Monday 2014 June 23
============================

Summary
-------
* Morning meeting with Rob, Brian, Nina (will make a regular thing)
* Updated good-3 spectra to link to background-2 spectra
* Added adjustments to XSPEC fitting (excise or fit silicon line)
* Updated `ds9projplotter.py` to parse arbitrary bands/labels/data/etc
* Generated new plots of 


More fitting stuff:
Calculate FWHM for those peaks where the data indicate a FWHM may be estimated
We need to revise the regions and the fit routine.

Guess: the error from overshooting the peak location, will be kind of large.
Possibly larger than that from shifting the profile around.

Brian short discussion:
* Quantifying Si line emission: one way is to give an "equivalent width"
(e.g. as in Winkler 2014).
* Splines -- yeah, fitting is better.  But you can try...


New energy band mosaics
-----------------------
(from Brian, today)
Solely breaking up 2-7 keV band

2-4, 4-7 keV
2-3, 3-4.5, 4.5-7 keV

Ad hoc flux-count conversions, for new bands
--------------------------------------------
* (2-3 keV) count <--> 4.5e-9 units
* (2-4 keV) count <--> 4.5e-9 units
* (3-4.5 keV) count <--> 4e-9 units
* (4-7 keV) count <--> 6e-9 units
* (4.5-7 keV) count <--> 6.5e-9 units


Tuesday 2014 June 24
====================

Summary
-------
* Twiddled profile fitting notebook to work on arbitrary bands/labels/data
* Tested further fit functions...
* Implemented (ugly, ugly code!) FWHM uncertainty estimation
* Calculated FWHM uncertainties.  But, not tested/debugged (and I know it is
  buggy)


More profile fitting antics
---------------------------

Try a two exponential function with split at x = x0, discard free parameter xs.
Now fiddle with initial guesses.  It looks possibly workable!  But, would need
to twiddle with the fits...

Try the Ressler function (With the split at x = x0).  This is going nuts.
It is having a hard time converging (even with 4x default max iterations
[maxfev], 8000 instead of 2000)

Revelation: the fits for simple cases (two exponential, two exponential
simplified) spewing out 'inf's are due to having errors of ZERO which kills
everything!  Ad hoc solution.


FWHM uncertainties
------------------

Trying to decode what Satoru did.
The scaling function goes bonkers for large positive xi, and goes bonkers for
negative xi (except, really small negative xi)

Using 50 arcsec. instead of 200 arcsec.
A tolerable range of xi to check seems to be [-1,0] and [0, 10]
But this depends on the region -- some are much stiffer than others.

Okay, kind of working now.


Wednesday 2014 June 25
======================

Summary
-------
* FWHM testing, and further work on the stretching function (to 1. verify FWHM
  values, and 2. understand behavior/effects of parameters)
* FWHM values and uncertainties, I think, are now reliable.


Profile uncertainties
---------------------
Satoru's uncertainty calculation: generate a new energy-band image (NOT
corrected for vignetting or exposure time) and count the number of photons in
each area.

Brian: will look for count mosaics, or generate new ones


Stretching function
-------------------
On one hand, this is almost as simple as you can get -- it's just a parabolic
stretch, instead of a linear one.  On the other hand, bad behavior occurs
easily when the stretch is extended too far.

With ad-hoc flux estimates for 0.7-1 keV band, the FWHM uncertainty in the
0.7-1 keV band is enormous!  In fact, if we didn't have the distortion that
occurs at large xi, the uncertainty would be even higher -- so we are
underestimating the uncertainty.


Thursday 2014 June 26
=====================

Summary
-------
* Generate count images + profile data from `merged_evt.fits`
* Compute uncertainties from photon count images instead of my flux-to-count
  estimates (not much difference)
* Slight tweaks to XSPEC fitting (constrain Si line fit, more reproducible and
  physically meaningful/relevant)
* Evaluate regions using profile + spectrum fits, and adjust to create
  "good-4-ext" set of regions.  No new regions added yet.


Count files
-----------
List of commands (just for record-keeping)
(also changing all instances of `4p5` to `4.5` for consistency...)

    dmcopy "merged_evt.fits[EVENTS][energy=700:1000][bin x=3300:4900:1,y=3300:4900:1]" 0.7-1kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=1000:2000][bin x=3300:4900:1,y=3300:4900:1]" 1-2kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=1000:1700][bin x=3300:4900:1,y=3300:4900:1]" 1-1.7kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=2000:7000][bin x=3300:4900:1,y=3300:4900:1]" 2-7kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=2000:3000][bin x=3300:4900:1,y=3300:4900:1]" 2-3kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=2000:4000][bin x=3300:4900:1,y=3300:4900:1]" 2-4kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=3000:4500][bin x=3300:4900:1,y=3300:4900:1]" 3-4.5kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=4000:7000][bin x=3300:4900:1,y=3300:4900:1]" 4-7kev_counts.fits
    dmcopy "merged_evt.fits[EVENTS][energy=4500:7000][bin x=3300:4900:1,y=3300:4900:1]" 4.5-7kev_counts.fits

From these, generate profile data with COUNTS only and extract the relative
errors (remember to account for integration length)

Spectrum processing
-------------------
Brian: to bound the linewidth, think about e.g., a Doppler broadening of
~10000 km/s.  In two directions that's 20000 km/s ~ 0.07c.  Energy 1.85 keV *
0.07 is 0.13 for a FWHM = 2.35 sigma, so sigma ~ 0.05 keV is as broad as you'll
get.

See the code in `spec_fitplot.py`, I have changed soft/hard limits on Si line
fit energies and sigmas (LineE strictly in [1.75,1.95] keV, sigma strictly less
than 0.1 keV).  This seems to constrain the lines very well.  No attempt to
fit the sulfur line at this time.

XSPEC equivalent width: value range is ~0.02 keV to 0.2 keV (typically 0.02 to
0.1 keV, only one case of 0.2 keV).

Region selection
----------------
See entry for `good-4-ext` in `data/notes-regions.md` to explain how new regions
are picked.

About 2/3ths of way through adjusting regions I accidentally hit ctrl-w one too
many times and killed my DS9 window.  So time to redo it...


Friday 2014 June 27
===================

Summary
-------
* Finish generating `good-ext-4` regions.  Generate profile data, and `good-4`
  without the thermal upticks
* Compute power-law exponents for each region (no averaging), estimate
  uncertainties in quadrature
* Test other profile fits -- smoothed (not-)interpolating spline, Gaussian +
  ramp function.
* Refactored profile fitting code for my sanity

QUALITATIVELY: using 1-1.7keV counts instead of 1-2 keV counts doesn't appear
to make much difference.

Uncertainties are still very large on FWHMs -- uncerts are comparable to those
for SN 1006, but the FWHMs are so much smaller...


Short meeting with Brian
------------------------
Went to Brian to discuss (1) how the exponents (`m_e`) were calculated in the
Ressler paper.  New regions, but basically almost the same as before.

Salient issues:
1. HUGE range of FWHM values being averaged together, to give a FWHM value,
   with small uncertainties (comparable to adding together / adding in
   quadrature) in the Ressler paper.
2. Relatively large uncertainties on computed FWHMs for Tycho (order 10-100%),
   vs order 1-10% for SN 1006.

Therefore, 

1. Test different profiles and see what happens (profiles need to hit the peak
   points, should not undershoot)
2. Go through output, see how many regions have positive/negative/flat trends
   in FWHMs.
3. Email Satoru and Sean, ask for some profiles to test our fitting routine
   on.  Should check that we get similar results, and similar uncertainties.
   This would confirm that the analysis is sensible.

So be prepared to bring this all in on Monday for discussion.

Profile fitting experiments
---------------------------

Verdict on Gaussian + ramp: doesn't work.  Has trouble accounting for steep
fall-offs and undershoots the maximum data values often.  But, it fits easily
and is not terrible.

How can I document / keep track of all these good/bad/middling fits?
So, the regions I'm keeping the region files to recreate them.
For the fits -- I need to refactor the code, and be able to regenerate them on
the fly.  So that's okay.  It would be good to record some comparative FWHMs /
uncertainties / chi-squares...


(Week 5) Monday 2014 June 30
============================

Summary
-------
* Checked SN 1006 profile fits from Satoru
* Fixed FWHM uncertainty calculation (after SN 1006 fits)
* List other ways to fit rim widths (functional models, + check literature)
* Calculate FWHMs from splines and manual-capping of max, to compare values
* Further refactor/clean up code

Catalog of regions
------------------
(n.b. gauged using old, large uncertainties -- now less relevant...)

How many show a downward, flat/upward trend?  Within error.
Looking at simplified, two exponential fits + errors on FWHMs; 4 band split
(0.7-1keV, 1-1.7 keV, 2-4 keV, 4-7 keV).

* Downwards: 1, 2?, 3?, 5?, 6?, 7?, 8, 9, 10, 11?, 12
* Flat: 4? except for 0.7-1kev, 13

Cases where at least two pts could be flat even:
1, 2, 3, 4, 5, 6, 10, 11, 13
i.e., most regions.

As noted before, the exponential fits have a risk of over/undershooting the
data peak.  So the FWHMs may not be reliable; I have marked those that may be
affected with a question mark (strictly by eyeballing).

In general, only a few have latitude for a FLAT trend; the rest may have 2 data
points side-by-side or so, but usually there is a decrease somewhere.  A few
cases (those without question marks) are unequivocal decreases.


Fitting checks (morning meeting)
--------------------------------
Main issue is uncertainties on FWHMs, now.  See meeting notes

Fitting Satoru's SN1006 profiles
--------------------------------

Observations:
* Satoru seems to have moved the peaks to all lie at ~50 arcsec
* The fit domain lengths are quite variable, though all strictly less than
  200 arcsec, it seems.  All the files he sent are 200 arcsec long,
  but the fit domains were cut appropriately in the paper

            0.7-1 kev band       1-2 kev band        2-7 kev band
------------------------------------------------------------------
Region 08   23.8 +2.0/-1.5      20.9 +1.0/-0.8      15.9 +0.8/-0.9
Region 10   33.4 +1.5/-1.3      30.7 +0.5/-0.5      26.8 +0.7/-0.6
Region 16   74.0 +5.2/-5.1      63.6 +2.1/-2.0      46.3 +2.3/-2.3

### Fitting using my procedure (as follows)

Procedure:
* I set the fit domain by eyeballing, to try to match the Ressler paper
* To work with my fit routines, I rotate regions 8, 10 (multiply by -1, and add
  100) to get them to work.

My uncertainty calculation will differ from Satoru's, because of the way I'm
moving the data around (not setting peak to one location, all facing same way,
et cetera).  If the uncertainties disagree, then these details may matter.

To follow my procedure, I translate/flip all profiles to start at ~0 with the
downstream side (closer to SNR) having smaller radial position.

Verdict: errors ~1 order of magnitude larger than what Satoru gets (!!!). WAT.
Absolute values of FWHMS are okay, although there is some disagreement.

            0.7-1 kev band       1-2 kev band        2-7 kev band
------------------------------------------------------------------
Region 08   28.4  +23/-12       25.0  +11/-8.3      22.8  +21/-13
Region 10   33.4  +5.6/-11      29.6 +4.5/-6.5      25.2 +6.4/-8.2
Region 16   73.4  +20/-54       63.4  +18/-28       44.9  +23/-25

Let's nail down what's going on.


Uncertainty calculation fix
---------------------------
(determined after looking at chi-squared criterion in paper, and looking at how
XSPEC does its chi-squared error estimation)

The `$\Delta \chi^2 = 2.7$` applies to the regular chi-squared, NOT reduced
chi-squared!!!!!  Please refer to Section 14.5 of Numerical Recipes (1st ed.)
(Section 15.6 of 3rd ed.).  So that makes things much better.

Now, the table (from above, using my procedure) looks like:

            0.7-1 kev band       1-2 kev band        2-7 kev band
------------------------------------------------------------------
Region 08   28.4 +1.4/-1.4      25.0 +0.8/-0.9      22.8 +1.3/-1.5
Region 10   33.4 +0.9/-1.1      29.6 +0.6/-0.9      25.2 +0.9/-1.1
Region 16   73.4 +4.1/-4.3      63.4 +2.2/-2.2      44.9 +2.9/-2.5


Rob: and that's why we do this, and beat our heads against the wall.
The region sizes are probably okay, remember the point is to just get
enough signal...


Fitting routine improvements
----------------------------
Goals:
1. Improve fitting to avoid overshooting on rim peaks.  Ideally, different fits
   should give comparable FWHMs and energy dependence.
2. Better characterize uncertainty

The exponential best captures the steep rims, just tends to overshoot too much.

### Improvements
* Pin FWHM calculation -- fix the maximum at the maximum observed data point,
  then calculate the FWHMs from that

> done: this makes for a helpful comparison

* Stretch in y-direction, see how that affects uncertainties?
  Could also allow stretch in both x,y directions.  Then uncertainties are
  determined by ellipse in parameter space, marking Delta-chi-squared ~ 4.71

> not done: likely won't do this; stretching in x-coord would have biggest
> effect on FWHM already, to 1st order, y-coord stretch will not change FWHM

### Possible functions
* Convolve 2-exponential model w/ some Gaussian or smoothing kernel
  How to fit something like this?

> Briefly tested -- convolving may work w/ fit, but makes it hard to solve for
> FWHM values since discrete convolution gives discrete data

* Some kind of penalty function

> Tested: cap on profile fit height kinda helps, although I suspect this
> worsens the fit and the height limit has no real grounding

* Hand fitting with two exponentials, manipulating/stepping parameters
  to get something that looks nice (no justification)
* Hand fitting with Ressler model, manipulating Gaussian to get good peak
* Fit a Fourier series
* Fourier filter a spline function (same vein as above)
  [example?](http://bigwww.epfl.ch/publications/unser9301.pdf)
* Cusp function (e.g., `$y = x^{2/3}$`), may not be steep enough
* Lorentzian? (likely not steep enough)
* Analytic, physical function (e.g., Berezhko and Voelk, 2004)

### Literature
* Araya et al.(2010) -- Gaussian fit to Cas A filaments
* Ballet (2006) -- no fits, no data
* Vink/Laming (2003) -- no fits, just eyeballed
* Parizot et al. (2006) -- fit exponential to downstream side, then use
characteristic lengthscale `R` to compute width as `w \approx 4.6 R`.
* Berezhko/Voelk (2004) -- analytically compute a long function (can try this?)
* Rettig/Pohl (2012) -- nab characteristic values from other papers!
* Bamba et al. (2003) -- SN 1006, two-exponential model (almost the same!)
  doi:10.1086/374687
* Bamba et al. (2005) -- multiple SNRs, two-exponential model
  doi:10.1086/427620

Experimenter bias: different fits will give very different FWHMs.  So it is
tempting to choose the fit function that, qualitatively or quantitatively,
gives the best/most consistent TREND in energy dependence.
But, there isn't really a good justification/confirmation for anything.


Tuesday 2014 July 01
====================

Summary
-------
* Fixed manual implementation of cap on fit function height
  (now verified to match calculation of FWHM, from imposing fixed "max" on FWHM
  calculation, for fit functions that overshoot data maxima)
* Calculating FWHMs for several function fits gives sizeable spread
* Reviewed list of possible improvements/functions (immediately above)
* Downloaded Kepler observations
* Quick calculation of power law fits to all band data to get `m_E`


Status of fitting calculations
------------------------------
Now calculating FWHMs by pinning either FWHM max or function to top of data.
Definite spread in FWHM values.

I favor two exponential model, simplified, over the two exponential model with
a free split.
Two exponential model with split usually gives FWHMs almost identical to
that of simplified 2-exp model.  In cases where FWHMs differ (model w/ split
gives smaller FWHM), the model w/ split has higher reduced-chi-squared -- at
least just looking at regions 2, 3 of regions "good-ext-4".


Questions/concerns on `$m_e$` calculation and interpretation
------------------------------------------------------------

* Which model do we favor, now?  Given the spread, especially when considering
  or ignoring the position of the data maximum.
  (and, I am thinking that constant offsets matter -- subtract background?)
* What to do about the spread in `m_e`?  How to average numbers for Sean's
  model?
* (to self -- continue to get an idea of the literature, and read what has been
  done before on nonthermal x-ray emission / filaments from SNRs)
* (keep an eye on the number of weeks left...)

sean's motivation for doing band-to-band fits instead of a 3 point power law
fit?

What went down in SN 1006?  Was there a lot of variability in each region,
before it got averaged out?



Wednesday 2014 July 02
======================

Summary
-------
* Polished up code for global fits to all data, for `m_E` calculation
* Started FORTRAN 77 tutorial
* Careful reading of Ressler paper, to understand variables/calculations in
  Sean's code (needs a few more careful readings).
* Push code/material to Github


For now... figure out what Sean's doing with the FWHMs.
Estimate mE for SN1006.
Figure out what the model code is doing.

Need to make small fixes to region picks and all that stuff!!

Lots of things to address by next Monday.



TESTING SEAN'S CODE:

with default resolution, B0=113, eta2=1.1, mu=1
it runs in fit mode pretty fast!
tring in plot mode, it didn't finish for about 16 minutes and I ctrl-c'd it.
So trying again while I run to get dinner, to see what it does.

Left it to run for about 1hr 20 minutes, nothing happened -- it was still just
spewing stuff onto the screen.

So plot mode looks like it does what it says -- calculate a ton of crap for
plots (I don't know what yet).


Thursday 2014 July 03
=====================

Summary
-------
* Discussion with Brian about Sean's email, paper calculations, next
  deliverables, questions, lots of misc. things
* Set up network printers on iMac!
* Finished bits of FORTRAN tutorial
* Walked through and cleaned up Sean's model code (`FullEfflength_mod.f`)
  (reformatted spacing, added many comments)
* Started debugging process (intensity profile output looks incorrect, from
  Sean's unmodified code)
* Sean/Steve/Brian/Rob email chain on model calculations

Today:
1. a little more time on FORTRAN and playing with Sean's code.
2. twiddle fit stuff, make spectra, etc.  Multiple small patches
    (a) in here -- run sean's analytic code, cuz that's really simple and
    straightforward.  Maybe do it manually, just to get some numbers
    that Sean/Steve/Brian/Rob can interpret/discuss!
    (b) new regions, new things, blah blah blah.
3. Make figures of regions, spectra in a multi-page pdf and send around to
   Brian, Rob, Sean, Steve, (Satoru?)
3. tabulate things, explain/write up things in LaTeX file
4. send things to brian/rob

Debugging notes
---------------

Ah, so the output from the fortran thing (both mine, and Sean's original)
suggests there's an error in the FWHM calculation ("box length error")
Add comma to variable declarations in FWHM subroutine? (between xmax/xmin)

I need to knife this thing with implicit nones everywhere.  Or just port it to
Python, or something.  For now, I just want to get it working so I can get some
numbers out.  Approach -- walk through code and comment EVERYTHING, then dive 
in to fix selected pieces (e.g. the box length error bug).  Then slowly add
improvements.  Not all at once.

Goal: for the FWHMs/`m_E` values reported for SN1006, be able to reproduce all
of Sean's calculated eta/B0 values.

I am getting strange results on the following inputs:
* B0 = 110d-6
* eta2 = 0.1
* mu = 1
* using fit mode (inu=2 and I set rminarc=100d0)
* default resolutions, as suggested

The code spews out numbers (something is going wrong), and the output is quite
strange.  Intensity profile output monotonically decreases with increasing
radius, from whatever the scaled radius is (here, 0.88 to 1); the 2nd column
(presumably 2 keV band) is all NaNs.  The FWHM calculations are being forced
all the way to the edge (i.e., it can't find a half-max!) -- and thus the FWHM
error, but really the error seems to be in whatever is generating the profiles.


(Week 6) Monday 2014 July 07
============================

Summary
-------
* Checked `m_E` calculations for SN 1006
* Sanity checks on `m_E` averaging, intensity vs. count unit usage
* Further clean-up to profile fitting notebook (separated FWHM computation
  and FWHM analysis/fitting)
* Began reimplementing / testing Sean's code for fitting equation (6)
  (catastrophic dump transport equation)


SN 1006 `m_E` values
--------------------
See notebook.  Verdict -- huge variability in `m_E` values as well, but
averaging FWHMs and computing `m_E`, or averaging `m_E` values, seems to be
reasonably consistent!

Computation of average `m_E`
----------------------------
A quick calculation: averaging the FWHMs then calculating `m_E` gives:

    m_E = \frac{1}{\log\left(E_2/E_1\right)} \log\left(
        \frac{ \sum_{i=1}^n \mathrm{FWHM}_{i,2} }
             { \sum_{i=1}^n \mathrm{FWHM}_{i,1} } \right)

I.e., we compute `m_E` using an _arithmetic_ average of the FWHM values.
Here we have `n` distinct regions; the 2nd subscript in 1, 2 denotes lower or
higher energy band respectively (equivalent to primed/unprimed variables, in
Sean's paper).

If we calculate `m_E` for each region separately, then average the exponents:

    m_E = \frac{1}{\log\left(E_2/E_1\right)} \log\left[ \left(
        \frac{ \prod_{i=1}^n \mathrm{FWHM}_{i,2} }
             { \prod_{i=1}^n \mathrm{FWHM}_{i,1} } \right)^{1/n} \right]

I.e., we compute `m_E` using a _geometric_ average of the FWHM values, this
time.

I'm not sure if that's helpful, but maybe something to keep in mind -- which
one would better capture the energy scaling?  Ultimately we want the best proxy
for the real physics, what's really going on, as independent of measurement
variation as we can get.

Looking at [Wikipedia](http://en.wikipedia.org/wiki/Geometric_mean#Properties)
and the relevant reference [Comm. ACM](http://dx.doi.org/10.1145/5666.5673),
I do think the geometric mean is appropriate.

Another intuitive/sketch argument: if we are averaging together small/large
numbers, random variation/uncertainty in large FWHMs could easily hide or smear
out the effects of variation in small FWHMs, when we know that the quantity of
interest is the _"normalized" variation_ between FWHMs, which should be
consistently calculable, to comparable uncertainties regardless of the size of
the FWHMs.

Filament 1 of SN 1006 shows this best (regions 1-4, not including 6).
The `m_E` calculated from the geometric mean is -0.39, vs. -0.16 from the
arithmetic mean (between 0.7-1, 1-2 keV).  Here region 2 shows a sharp drop in
rim width, but the FWHM values are quite small.  So when averaged, the larger
FWHM values predominate; as they show a smaller change in width with energy, so
the magnitude of `m_E` is smaller.  But, the geometric mean recovers the
scaling of region 2 -- weighting it equally, in a sense.

(note, we haven't considered errors/uncertainties here -- this also matters).


Calculating `m_E` with intensity units
--------------------------------------

Using total counts vs. intensity flux units, gives very different values for
`m_E` point to point, and some variation in FWHM calculation.  To check this, I
compute FWHM values from count units and flux units, and compare the FWHM
changes in different energy bands (similar to what was done for 1-1.7 keV vs.
1-2 keV).

Result: it seems like there could be a small shift in FWHM value.  But, the
FWHM shifts are distributed about zero, both positive and negative, and the std
deviation is much larger than the mean.  So I think we can neglect this, and
say that it doesn't matter much.  Besides, we should use intensity units rather
than count units (because of the exposure/vignetting correction).


iPython notebook cleanup
------------------------
Damnit this is always cringe-inducing to stare at.

* Moved fit functions to a separate module (but, fit routines which supply
  initial guesses, run multiple fits with frozen parameters, etc are kept
  within main notebook).
* Moved main functionality out into separate method, to minimize global
  namespace pollution...  now, just run ONE cell and it will populate
  the region dictionary with information (fits, fwhms, etc)
* Brian on software maintenance vs. research time: something we all deal with,
  right?  Remember to think about cost-benefit analysis, how much time it's
  gonna take.  Put in the time necessary to make it work for you.
  And, will you reuse it many times, or is it a one-off thing?

Main change: moved FWHM fitting functionality (all calculation of `m_E` and
similar) to new notebook.  Profile fitting notebook now outputs plaintext and
serialized objects (Python pickles) storing information about regions.


Plot of region profiles and spectra
-----------------------------------
Basically, mimicking Figure 8 of Ressler et al.
Some remarks from quick drop-in with Brian, today.
* Plot spectra and fits out to 0.5 keV, to show minimal oxygen line emission.
  Steve (Reynolds) has been worried about thermal emission, need to show that
  spectra are clean.
  Oxygen line is at about 0.56 keV.  Expect Tycho to have relatively little
  oxygen (a fraction of a solar mass).
* No need to do the two spectra as for SN 1006.  We don't have enough room
  behind the rim to get clean (nonthermal) spectra, and what they tried to show
  in SN 1006 (that rims do thin with increasing energy), is somewhat redundant.
  (and, not quantitative anyways, without spectral indices)
* Yes, go ahead and make a nice multiple panel plot now -- do once and be done
  with it


Sean's analytic model fitting (equation (6))
--------------------------------------------
Migrated Sean's code to iPython notebook to parse FWHM-energy values.
Slight cosmetic changes / moved things around, but otherwise should be the same
(need to provide a version of code that validates this).


Tuesday 2014 July 08
====================

Summary
-------
* Generated preliminary Tycho numbers from Sean's approx/analytic fitting code
* Rearranged directory structure for clarity
* Updates to profile fitting code
* Added/tested script to split regions at FWHMs/fit edges, for spectra


Fits to equation 6
------------------
Some brief remarks.

1. I'm seeing fields of order 0.1 to 1 mG (mostly 0.1 to 0.5)
2. If I use "capped" FWHM measurements, and/or change the distance estimate
   from 2.3 kpc to ~4 kpc, I get slightly smaller numbers -- but I haven't
   quantified this, just eyeballing.  I cannot tell whether fits are better
   with capped FWHM measurements or not.
   Fits in general are not very good -- large residuals abound.
3. Concern from yesterday -- errors, as computed for confidence intervals by
   varying parameters (exploring chi-squared space), are quite large!
   Especially compared to 1-sigma from the parameter standard deviations.

At least, qualitatively, the numbers are consistent with what Parizot et al.
(2006) give (~250 to 500 microgauss)


Directory re-organization
-------------------------
To more easily track where files are located, and to allow for easier
experimentation/extension to the pipeline structure.
Pipline organization idea borrowed from Software Carpentry lecture on data
management: [link](http://software-carpentry.org/v4/data/mgmt.html).

WARNING: this breaks links between spectrum files.

My proposed directory layout follows.  It will likely be updated (because
that always happens) but I hope the general structure can be consistent.

    data/ *.fits
          README.md
          notes-regions.md  # Describe how regions are selected

          region-ID/ README.md  # Describe how spectra/profiles are derived
                     *.reg      # from region files (scripts, dates, cmds)
                     *.ciaoreg
                     *.physreg
                     *.jpg  # Images of regions on SNR, etc
                     *.pdf  # Multipanel plot of spectra/profile

                     spectra/ *.pi  # IF multiple sets, push to folders
                              *.rmf
                              *.arf
                              plots/ *.pdf   # Plots of spectra/fits
                                     *.ps
                              fits/ *.txt  # Fitting information
                                    *.qdp  # from XSPEC, etc.

                     profiles/ *.dat  # If multiple sets, push to folders

                               plots/ *.pdf
                                      *.png
                               fwhms/ *.pkl
                                      *.txt
                                      plots/ *.pdf  # e.g. Fig. 10 of Ressler
                                      model/ *.txt  # Modeling results?

          background-ID/ README.md  # as for regions
                         *.reg
                         *.ciaoreg
                         spectra/ *.pi
                                  *.rmf
                                  *.arf

    code/ regions/
          spec/
          profiles/
          models/

Or something similar.  Exact arrangement of profiles/fwhms stuff TBD.


Updates to profile fitting
--------------------------
* Define some magic constants (smoothing parameters, labels) in "configuration
  cell" and output config log to document code inputs/outputs.
* Serialize fit function as SOURCE CODE, instead of function object, for
  interoperability (else pickle file requires access to function's
  containing module).  Also opens opportunity to use JSON for data exchange.
* Improved output for spectra generation and FWHM processing farther along the
  pipeline.  Note that the Python pickle (serialization) also includes the
  fitting function and best fit parameters, so that does document the fit used.


Spectra generation
------------------
Spectra locations will be set by FWHM and profile fit locations.
After computing FWHMs and profile fit domains (smoothed local minimum cut),
notebook/script saves cut and FWHM locations to pickle/text files.

A script should read the cut/FWHM locations for all regions,
generate TWO new region files -- one with fronts, one with backs,
then use ds9proj2box.py to convert to CIAOREG, then feed through specextract
chain.


ds9projsplitter.py + pipeline updates
-------------------------------------

Got script `ds9projsplitter.py` working.  After discussion with Brian, we
decided to plot spectra from two regions, kind of following what Satoru did in
Sean's paper.  Updated `ds9proj2ciao.py` as well.  Some misc. notes follow:

* Running into issues with multiple copies of ds9 opening, again.  Once ds9 has
  been opened/closed in a Python session, it won't open again (can't find the
  ds9 instance).
  STUPID SOLUTION: reload the ds9 module (`reload(ds9)`).
* Added blacklist to profile fit code (convert FWHMs to NaNs if blacklisted)
  Blacklisting guideline: if FWHM could not be calculated from 2exp fit, or
  the spline/capped fits could not get a FWHM (i.e., without overshooting we
  could not get a FWHM), add to blacklist.  Kind of adhoc and subject to bias,
  but good enough.
* Cut locations are determined in profile fit code, so they can be saved to
  region dictionary for plotting later on.
* Updated XSPEC fitting script to fit 0.5-7 keV as requested by Brian (confirm
  no oxygen line at 0.56 keV).

Also ran specextract on the upstream(rim) / downstream regions.


Wednesday 2014 July 9
=====================

Summary
-------
* Improved XSPEC fits + fit output
* Plotted spectra from upstream/downstream split on regions-4
* Generated first iteration(s) of multipanel plots for distribution


XSPEC fitting output
--------------------
Script now generates:
1. plain XSPEC log file as before (with equiv. width + 90% conf. errors)
2. json file with fit parameters, errors, fit statistic
3. npz file with spectrum data+errors, folded model, and background

Also added option to generate 90% conf. errors, as it is time intensive + error
prone + may require user input.

Some notes from debugging/etc:
* matplotlib.pyplot doesn't work with 32 bit python -- need to reinstall
  matplotlib and build from --universal installs of libpng, freetype libraries
* After much finagling -- to get spectrum data, use xspec.Plot object
  attributes (which returns the values used for plotting).
  Spectrum, model attributes give raw data for channels, not energy bins.

Result of upstream/downstream divide
------------------------------------

From regions-4, it looks like the rims are pretty clear of thermal emission.
Downstream of the rims is fairly contaminated -- silicon line is usually
visible, often sulfur as well, and some other lines.

The plots don't seem to be scaled by area -- units are "normalized counts per
second, per keV".  Satoru's plots (Figure 8) have units "cts/s /keV /cm^2".
How do you do that in XSPEC??  One link about this normalization issue:
[link](http://heasarc.gsfc.nasa.gov/xanadu/xspec/manual/XspecWalkthrough.html).
Not very helpful.  In PyXspec, spectrum object attribute `areaScale` is 1.0,
which I suppose is the EFFAREA keyword discussed (ctrl-f on "normalization").

It seems like we must scale by detector effective area -- how do we do this?

Downstream regions, with contamination, can't get 90% confidence errors.
The reduced chi-squared values are too large, so XSPEC errors out.

Plotting
--------
Usual spiel -- play with opacity, color, plot markers.  I think it looks pretty
nice.

My default matplotlibrc (fontsize 9 everywhere) is good for pdf output,
hopefully for publication ready figures.  But, it is not so good for viewing
output within a notebook.  So that needs tweaking, depending on how we present
this.


Thursday 2014 July 10
=====================

Summary
-------
* Tried generating plots of FWHM dependence for multiple regions together
* Walkthrough of script for generating spectra from all 750ks of Chandra data
* Added rich images/text etc to profile/spectrum plotting notebook


Region + Tycho images
---------------------
Need to use box regions, to get rid of dashed lines (projections).

1. convert to ciaoreg
2. apply format changes (save as -img.reg, with text regions)
3. crop RGB tycho image
(center on RA, dec = 6.334 deg, 64.137 deg; size 0.17 x 0.17 deg)

Try: 6.324, 64.143 (ra, dec in deg)
0.165 deg square


Plotting notebook
-----------------
Add plots of FWHM dependence, nice images of Tycho regions, tables of FWHMs
(using snippets of HTML).




Friday 2014 July 11
===================

Summary
-------

Plotting notebook updates
-------------------------
Fixed tickmarks and stuff
Discussion with Brian about FWHM presentation

Hide cells / reformat output?  If it takes ~half an hour sure but not if it
takes a half a day.


Specextract scripts
-------------------
Twiddle paths/setup to work

Acting on regions-4-up and regions-4-down,
the script took about 1 hr, 50 minutes for each set.
So, in total, expect ~4 hr (including set-up time).
Don't let the computer sleep while running.

Plotting notebook changes
-------------------------
Many changes -- Discussion with Brian yesterday and today)
Simple way to think about it -- we have a 3-D space with the axes:
* region / filament number (i.e., arbitrary ordering whatever)
* FWHM measurement
* energy / energy band


More SNR data (Kepler, Cas A)
-----------------------------
Redownloaded one of the ObsIDs and finished reprocessing everything.
Now, testing out `merge_obs` using:

    merge_obs "6714/repro,6715/repro,6716/repro,6717/repro,6718/repro,7366/repro" out/ bands="csc" verbose=3

I don't know what energies to pick, to evaluate the exposure map...
Started at 8:41pm, Friday July 11, computer set to not sleep.
Finished at 8:57pm?  Dang, that was actually pretty fast

Pretty images!... man.  But they're too small.

FOOL.  You forgot to set the bin size to 1, no wonder!...  Try again at 9:18p
Finished 22:34 (so, ~1.5 hr. okay, not terrible).

Download Cas A meanwhile.

Saturday 2014 July 12
=====================

Using grppha with group min 15 on the total spectra...
Ran the rest of the pipeline on the spectra, twiddled scripts.

Profile plotting notebook now has full spectra + fixes suggested by Brian from
Friday.  I have a super, super hacky workaround for the website issue --
just use

    ipython nbconvert --to html plotter_prfs_specs.ipynb

Then go in and search for `<div>` cells like:

    <div class="text_cell_render border-box-sizing rendered_html">

    <div class="cell border-box-sizing text_cell rendered">
    <div class="cell border-box-sizing code_cell rendered">

I'm very perplexed because the `</div>` tags seem to be crazy mismatched.
(and, I can't believe that pandoc is just embedding images inline...)

Okay need to clean up these notes soon but I think I'm done for today.


Monday 2014 July 14
===================

Continuing issue - how to best deal with FWHM presentation?
* Normalize averaged values, or average normalized values
* Error calculation -- Sean's procedure, or std. err of mean

Brian suggests using Sean's procedure for now for consistency, discuss with
Rob/Steve/Sean/Satoru what to do.

Note -- textmate doesn't properly fold all div tags...??? I'm not sure
actually, pandoc's nbconvert output is just a mess.
Add width to notebook-container div tag, to manipulate webpage width (I set it
to 1240px for now...)

Emailed website to Steve/Sean/Brian/Rob

So need to
1. overhaul specextract pipeline (handle region coordinates correctly, test and
   ensure it works correctly with my adjustments)
2. rehaul data structuring for FWHMs because it's a pain in the ass to plot /
   organize
3. include switches to test different measurements/procedures, for
   reproducibility.
4. proper config files / cmd line arguments for fitting/FWHM analysis scripts?
5. clean up rsch notes document... keep track of what changes/etc I've been
   making

Code -- how to refactor, how to best manage, how to ensure reproducibility?
Mulled on this a while

Tuesday 2014 July 15
====================

Summary
-------
* AAAAAAAAAAAAAA
* Code writeup, review of models and physics, sent to Brian
* Figured out discrepancy with Sean's usage of diffusion coeff eta2 in code


Code refactoring -- stared, sighed, and moved on to Sean's model code again
(which is both more doable and more fun)
k

Start writeup of code -- finally figured out the weird variables sean uses,
although it doesn't explain his choice of variables when explaining parameter
space (but fortunately NO ONE CARES).


Wednesday 2014 July 16
======================

Summary
-------
* Reviewed most calculations in Sean's code (e- distribution functions TBD)
* Debugged Sean's code to a point where it seems to work
* Emailed Sean with various questions...

Slow hard debugging of emissivity integrals etc...
Anyways I cleaned up the emissivity code
Happily, it's now giving sensible numbers!!!
My test case is B0=0.0001, mu=1, eta2=1
I get 33.45" at 1.00 keV, 26.85" at 2.00 keV
with m\_E at 2.00 keV being -0.32

The output intensity plots and electron distributions look very nice!
For this very simple case.  I don't have a sense of when/how it will blow up,
yet.  And I haven't run any timing tests.

Started looking into the synchrotron spectrum numbers and stuff...
Checked out Shu, Shu, and Pacholczyk


Thursday 2014 July 17
=====================


Updated simpson's rule implementation (changed coefficients to be more
consistent with, e.g., wikipedia article)
Results for test case (B0=100d-6, eta2=1, mu=1):
33.75" at 1.00 keV, 27.00" at 2.00 keV, with m\_E = -0.32 at 2 keV.
Okay, looks good, just a small change.  Also added middle pt to integration
(divide by two).

Checking electron distribution functions - change of variables (check the math
and check the behavior at singularities -- some ad hoc fixes seem hardcoded.

(then, afterwards, walk through synchrotron derivations and constants)


Friday 2014 July 18
===================

After spending some time on math this morning, and talking briefly with Brian,
rederiving/checking equations should be set aside.  Check that equations in
code agree with equations in text -- but, get code working, get numbers working
first.  We only have 3 weeks!!!

And -- Steve, Sean have certainly vetted this work.

Main result from math -- Sean gives some long solution to equation (12) without
diffusion, which should be easy to derive -- it is a 1st order linear
nonhomogeneous PDE, use method of characteristics.  But I can't remember my
basic PDE stuff (other than all the 2nd order stuff from electrostatics etc...)


Main result from integrals -- term in exponential argument has a factor of $-1$
which I can't account for.


Went through ALL of Sean's original code...
NOW, check his magnetic damping version of code (which looks a bit newer
actually) and see if anything needs to be updated fixed...
Welp I'm done... don't want to go through that and spend 4 hours cleaning it
up.

need to resolve Ecut issue!

Then... change it up to work with f2py easily.
Then... try porting it if that doesn't work / runs into trouble...


Monday 2014 July 21
===================


Resolved Ecut issue.  Sean's code is correct, paper equation (18) has a typo,
follow equation (19).  Funny exponent formatting is to make it easier to work
with the prefactor.

Figured out how to get numpy f2py running, and compile fortran code into python
module

Remove widthfun\_mod.py which didn't really add/change anything, since the code
for that is in another folder now.

Copy working version of FullEfflength\_mod.f to backup -- because this is close
to the intent/design of Sean's code, and now messing with f2py I am going to
start deviating substantially by altering the inputs/outputs functionality.

Okay, now setting up python wrapper to fit function

Remove "options" in code for fitting/plotting versions -- should be superseded
by python control, if we need to generate plots or other things.
For Sean's plotting code, he changed rmin with each change in nu?!
with `rmin = 1d0-(1d0-rmin)*((10d0)**(-.25d0/16d0))`, small 

Updated code to accept arbitrary number of nu arguments, in keV...

geezus this really shouldn't take that long to do :(... be efficient, dammit.


Running fit code with scipy.optimize.leastsq
changing epsfcn=1e-6 finally got it to do more than 5 iterations
(with mu=1, eta2=1 fixed, b0 initial guess=1e-4, filament 5 from sn1006
I got 16 iterations, and b0=108 microG.  Ehh... better than before?!
It actually looks like a tolerable fit (just looking at numbers...)


Tuesday 2014 July 22
====================

Quick profiling of code: takes 33 seconds to run that (16 calls).
So if, e.g., I am to grid over 100 points in B0, 100 points in eta2, 20 points
in mu, thats 200,000 function calls = 400,000 seconds = 111 hours = 4.6 days
(!).

Let's say, 10 points in mu, 20 points in B0 (logarithmic space, 10 microgauss
to 1000 gauss?), 20 points in eta2 = 4000 points, at say 4 seconds each (to be
conservative, with 5 bands), we have abt 4.5 hours.  From there you can refine
the grid as needed -- need to list configuration parameters, and make it append
only or something like that, so you can keep adding more numbers if needed?
(think adaptive meshing ideas)

play with rminarc etc appropriately, run a few TEST CASES for
SN 1006 specifically, or Tycho specifically, before you generate the table)
*list test case procedure for table computations (grid resolutions, rminarc),
in some kind of nice readme*.



Perhaps the best is to downsample by a factor of about 10-100, and make a small
grid of values -- FWHMs with normalization and m\_E values.

First thing: try to replicate fit with lmfit, now.

with lmfit: 42 seconds, converges to 110.7 microG

For quick reference, comparing best fit values with eta2=1, mu=1 fixed
computing chi-squared values by hand, for SN 1006 filament 5 average values
data = np.array([33.75, 27.2, 24.75 ]), eps = np.array([2.37,.62,.61])
    plain leastsq: B0 = 108.60
        FWHMs: 33.9, 29.7, 24.0
        chi-squared: 17.77
    lmfit wrapper: B0 = 110.68
        FWHMs: 32.85, 28.8, 23.25
        chi-squared: 12.85

NOW, if I let eta2 go free (mu=1 still fixed), I get 26 calls and best fit:
    lmfit wrapper: B0 = 123.223 microgauss, eta2 = 2.075
        FWHMs: 31.35, 28.2, 23.85
Compare to Sean's paper:
    B0 = 206, eta2 = 80
        FWHMS: ... what?!

right -- remember that some of the filaments / labeling / etc are incorrect...
maybe best to use a well vetted filament...

Now is perhaps the time to discuss -- how do we best compute and present fit
results?  for individual regions, individual filaments, ?


I need code to call function and get output values...
and compute chisqrs quickly.


Need a plan of action -- first how to validate this code against SN 1006, then
apply to our results.  Run it by Sean.
Maybe in the paper we can present new results for SN 1006... following a more
consistent procedure.

Confidence intervals -- messing with resolution and rminarc.  This will be
fun...


Remarks from Brian (throw this into a meeting notes file / replicate in agenda
/ whatever):
* Williams et al. (2013) reported shock speeds assuming 2.3 kpc, just rescale
  by multiplying with factor 3/2.3
* Grid idea sounds good (generate grid, use that to find good initial guesses
  and to just explore / look at parameter space, check degeneracy / trends)
* Okay to just generate grid over a few days, not that bad.
* I noted that our work would disagree with SN 1006 values, no big deal.
  Try to reproduce Sean's numbers anyways and sanity check the code !!!
* Consider: compute values / fits for all the regions individually, since our
  data/signal is so good, and then average the output values of mu, B0, eta2.
  Keeps more salient information, maybe...
* Don't worry about 2 regions/filament, it's okay for now.
* Gridding -- be smart about it, pick grid points appropriately.  E.g. you
  probably don't need to do B0=500, B0=600 (microgauss)... if the relationships
  are linear, stuff behaves nicely

Send around tablesssssss (Monday meeting), do Table 7 (simple model) meanwhile,
Table 8 soon (so that's all in the works).
Remember the poster..

Eventually clean up the last week of messy notes / agenda!... but for now I
want TABLES TABLES TABLES.

ALSO NEED TO PLAY WITH THE LEASTSQ KWARGS -- THE STEP SIZE ETC WHAT HAPPENS
WHEN YOU CHANGE THAT (doesn't matter for the grid fit -- but for a naive fit it
will matter... and it will matter if the grid is poorly sampled, not well
reflecting chisquared space)


Thursday 2014 July 24
=====================

Added code to make interactive manual fitting easier (remember best fit and
plot data with fits interactively).  Not perfect but no need for more bells and
whistles right now.

I note that the naive fitting code (i.e. throw numbers into lmfit with some
initial guesses for eta2 and B0) is actually not working that well.
Essentially, it's not exploring enough of parameter space, especially if its
initial guesses are bad.  Or, rather, you might say that the parameter space is
too messy, littered with local minima...

Messing with epsfcn parameter (i.e., step size knob) slightly.  This will not
save us.



So, next step in validation is to generate a table for SN1006...


For Tycho -- generate tables with slightly different shock velocities / plasma
velocities, and see how they differ.

Compression ratio doesn't relate 1-to-1 with widths / magnetic fields (how does
it work, what does it do to the filaments/plasma?).  But yes, generate numbers
with 1/6 instead of 1/4 and see how it looks (hard to get smaller compression
ratio, Brian says?)

Another thought -- we are treating this all as a steady state process.  Seems
reasonable given the velocities involved (is there an equilibration timescale
for advection-diffusion equation?)

Finally, the grid is going to be kinda messy.  Twiddling the parameters too
much, blows things up real fast.

Increase or decrease B0, set the range dynamically -- or even could do so
manually, basically imitating what Sean did.  There is degeneracy in that
B0 and eta2 are correlated -- both strongly affect the overall size of FWHMs,
but only eta2 will affect the scaling.

Following the approximate equation of Parizot et al...
I have that, for roughly constant/consistent filament amplitude,
eta2 propto B0^(mu/2 + 1) should be maintained (makes sense at mu=0, one to one
scaling because with mu=0 implies diffusion just stretches/shrinks filaments by
a small factor... neglecting messy transport and stuff.

If diffusion is strong, this should be eta2 propto B0^(mu/4 + 5/4)... pretty
close relation.  They agree if mu=1.

Because diffusion doesn't seem to be strong most of the time...
let's go with eta2 propto B0^(mu/2+1) for the grid generation.
and allow the values to covary around this approx scaling relationship.

But I think this breaks down eventually.  As eta2 goes to zero B0 does not go
to zero...

Aha -- you have to deal with the singularity correctly as mu goes to zero!

Result:
Turns out that attempting to use the theoretical scaling (i.e. from my math and
derivations) failed horribly.  Numbers were way off the mark, and I couldn't be
bothered to try to fix/correct it.  Easier solution is to just fit the simple
model directly because that gives good, physically sensible numbers

    # Me attempting to compute values in B0, eta2 space by
    # SOLVING equation (6) directly.  Needless to say, this failed badly.

    #b = snrcat.SYNCH_B
    #cm = snrcat.SYNCH_CM
    #Cd = snrcat.CD
    #nu2 = snrcat.NUKEV * 2.0
    #v0, rs, rsarc = snr.v0, snr.rs, snr.rsarc
    #a = (30/snrcat.BETA) * rs/rsarc # Scale length = fwhm / beta
    #B0_vals = np.linspace(75, 300, 10) * 1e-6
    #eta2_vals = (a*v0/Cd * (nu2/cm)**(-mu/2) * np.power(B0_vals, 1 - mu/2) *
    #    (a*b/v0 * np.sqrt(nu2/cm) * np.power(B0_vals, 3/2) - 1))

    #init_B0 = 208e-6
    #init_eta2 = 80.0
    #c = init_B0 / init_eta2**(1 / (5/4 + mu/4))
    #eta2_vals = np.logspace(0, 2.5, 10, base=10)
    #B0_vals = c * eta2_vals**(1 / (5/4 + mu/4))
    #np.insert(eta2_vals, [0.01, 0.04, 0.1, 0.2, 0.5], 0)
    #np.insert(B0_vals, 5*[B0_vals[0]], 0)

So I moved on to fitting the simple model directly


Main conclusion (after generating values from fits) -- in the SIMPLE model
no matter the value of mu,
the best fit value of B0 is propto (eta * (E\_h)^(1-mu)) ^ (1/3)

but at small eta2 (negligible diffusion) B0 levels out as a constant.
The leveling off is quite sharp, so a simple powerlaw + constant doesn't quite
get it.  But it doesn't matter because we're already using an analytic
function.


....

much fiddling later, this is hard. whee.  I have a better grip on what's going
on in parameter space, and on the subspace of acceptable physical parameters in
the parameter space.

The best fit value of B0 is certainly not unique, nor guaranteed to be found...
And, at any rate -- adding min/max bounds doesn't help it converge any faster

some numbers (on a grid of mu, eta2, find the best fit value for B0 using full
numerical code, on filament 5, mu=1...)

    measured:   33.75, 27.20, 24.75
    simple fit: 35.52, 29.74, 21.09

epsfcn=1e-5

    B0 = 92.177 muG
    full fit:   36.45, 30.30, 21.30
    chisqr = 58.29

epscfn = 1e-4

    B0 = 91.797 muG
    full fit:   36.45, 30.45, 21.45
    chisqr = 58.04

epsfcn = 1e-1, epsfcn=None

    B0 = 93.263 muG
    full fit:   35.70, 29.70, 20.85
    chisqr = 57.81

epscfn = 1e-2

    B0 = 92.661 muG
    full fit:   36.15, 30.00, 21.15
    chisqr = 56.25

Conclusion: parameter space SUCKS... what's going on here? why is it so bad?

One possible effect is the finite intensity profile resolution.  
If you change B0 or eta2 or other parameters slightly, the exact FWHMs may
not jump instantly. rminarc = 60 arcsec, with 400 grid points, gives discrete
step size of 0.15 arcsec.

(if I twiddle rminarc or other parameters, the results will change
subtly as well.  But the hope is that it doesn't really matter)

Lastly, these are really bad quality fits -- the best fit eta2 is between 1
and 10.  MAYBE the fits are more robust there?  But, honestly, with fixed eta2
and mu it shouldn't matter -- as we see in the plots of chi-squared vs. B0, at
fixed, where we are gridding on mu and B0 and doing a fit for eta2, the best
fit value of B0 is usually very well defined.

But the spread is small enough and almost certainly within uncertainty, is my
guess.  Yes -- all within delta chi-squared = 2.7 (super ad hoc, empirical, not
scientific, not rigorous, not sampling the space of possible outputs from fit
convergence).

So I think we have no choice but to grid over the space, as finely as possible
(the spacing in eta2 matters much more than spacing in B0, actually.  And the
mu spacing is not so important.)


Give qualitative observations of fit behavior, chi-squared space (from simple
fits) for each filament, alongside my best fit results from simple and complex
models.
And, in all work, use the simple model as a guide to what's going on.


Thursday 2014 July 24
=====================

Summary
-------


Tabulating FWHMs in (B0, eta2, mu) space
----------------------------------------




Idea: SNR class should store (slightly more transient) information about
filaments, regions, etc... ?  Idea is to keep all information together.



I think it's worth plotting a scatter of the tabulated grid values.
And, then, plot the simple model best fit (maybe for multiple/all filaments)
to show that our tabulation range is consistent with where we expect real
filaments to lie..........


Currently -- formulating algorithm to generate grid points...
I am worrying about overshooting (if derivative is ever near zero, this
Newton-Raphson procedure is essentially gonna blow up.  YEAH -- this part of it
is simply rootfinding, except trying to hit y\_Final instead of y=0).

But -- for our purposes, since we are fitting B0 to widths, there should be no
local minima/maxima -- the function should be monotonic, and the derivative
should not be small.

Happy solution -- iterate along function until we reach FWHM (Rscale) min, max limits.
Then, use `mind_the_gap` to fill in the rest of the data points.


Some very simplistic test cases shows it works nicely.  Great.

Continued work until it seems to work on FWHM tabulation and all, generates
proper grids in eta2-B0 space.  Mostly


Friday 2014 July 25
===================


Debugging full model gridding code.  A few different small issues coming up, as
I test the code on certain edge cases (e.g., when the initial guess for B0 is
bad, and/or `r_init` falls outside of range [0,1])

Next I need code to work with the results... i.e. perform simple/complex fits,
and save/tabulate the most important numbers.  Also adapt hte complex fit
gridding code, to accept arbitrary grid inputs... -- this will let us pick up
the code where it left off, if it ever breaks / running is interrupted, as long
as we save to a file continuously.

First let's do simple fit, to have stuff to talk w/ brian about.
then complex fit to test the table.



Plot point-to-point measurements of `m_E` as a function of energy, get the
scaling -- what does that tell you?  Just to get a qualitative feel on how
`m_E` scales...


Preliminary test -- dammit, filament 2 is not resolved in chi-squared space,
these are NOT best fits..


Realization: we really need FWHMs outside of the limits, set by FWHMS -- to be
able to find the best fit B0's for those filaments near the limits...
Filaments 2,3,4 are crap (2,3 especially, some in 4 barely find that
chi-squared minimum)

even if we have 



Key idea: even though for most fits, we don't need to compute this many values
of B0 (we are over sampling chi2 space and doing so in places where its not
needed),







Problems on the horizon:
if I'm generating values for eta2 inconsistenly some places I will be able to
find best fits, some places I will not.... might be better to regenerate
tables....


Resolving eta2 is a big problem.  Remember to throw in some linear values per
Brian's suggestion.


Weird problem: code bugs out on rminarc=73.71
The bug is due to f2py, not my code ?!?!?!?!.
It goes bonkers on VERY specific values of rminarc (e.g., 73.71), but works on
other (say, 73.72)

Quan suggests, astutely (or I may simply be ignorant of common bugs in
numerical computation / lower level stuff...), that it may be due to floating
point error.  Sounds plausible...

Anyway the key takeaway is that we cannot adaptively adjust rminarc




Try saving to new file after every set of B0's (every eta2)...


Useful note: of course, output FWHMs are resolution dependent. at rminarc ~60, error
~0.1 arcsec (which is order 3%)

Okay need to clean up these notes but the code is running and the bug is set
aside, for now.


Saturday 2014 July 26
=====================

Summary
-------
* Code cleanup
* Split code -- one file for tabulating/model fitting, one for running fits
* Download and check Tycho shock velocity values
* Start Tycho table generation


Start the gridding process for Tycho.
Useful to know -- with max fwhm = 10 (my arbitrary setting), times 1.51 to get
a large range of fwhm in table, times 1.2 to get a factor of safety,
rminarc = 18.12 for these simulations

Compare rminarc = ~90 for SN 1006 (74.1 max, * 1.2 safety) gives abt 0.2 arcsec
resolution on FWHM values, vs. about 0.05 arcsec for Tycho.  So okay, even the
FWHMs of about 1 to 1.5 arcsec will be resolved all right.


Quick remark, on selecting shock velocity values for gridding:
Tycho shock velocities vary up to a factor of two!...
2000 to 4000.  But, a majority of Brian's measurements found it to be around
3000 to 4000 -- excluding one odd data point near the north.
Aha!  that data point appears to be associated with that tuft of thermal
emission, so we are definitely sampling the shock at its fastest locations...

Conclusion -- worry not so much about data near 2000 km/s, unless I get any
regions in the thermal eastern bits.

REMEMBER THAT BRIAN ASSUMED D = 2.3 kpc.  WE ARE TAKING D = 3 kpc.

See a short txt file on velocities I added.  Summary -- start by taking
`vs = 3600 * 3 / 2.3` as vs; the range in the non-thermal shock regions is 3110
to 4060.  And, 3600 (3580 without rounding) is the mean and median of the data.
I am omitting veloc. measurements in the thermally contaminated areas


Remember -- we are curious about the effects of:
* changing compression ratio (changes v0 only)
* changing shock velocity (changes both vs and v0)
* changing distance to remnant -- this works TWO WAYS. (1) if we increase
  distance alone, not veloc., this widens the rim widths, and we need weaker B
  fields or stronger diffusion to compensate.
  (2) if we increase distance, and increase shock veloc. correspondingly, the
  increase in veloc. would help "explain" wider rims, so this counters the
  previous effect.  Two competing things here.

Also, this is kind of obvious... but given the great range of possible B0 and
eta2 values (because we will have enormous uncertainty on the best fit, which
we will investigate in chi-squared space?), it would be good to be able to
constrain one or the other.  If we can cap B0 somewhere, that allows us to also
cap / favor / limit eta2 values.  And, perhaps, mu.  Time for statistics?

SOME RESULTS (interpretation and accounting for asap...)

    Simple model fits, Tycho, region 1
    Using mu = 1, data: [ 2.72  2.2   2.22  1.88  1.9 ]
    Investigating effect of changing shock velocity
    Shock velocity = 2.50e+08: mu = 1.00    eta2 = 2.28 +/- 2.14    B0 = 489.36 +/- 114.65
    Shock velocity = 4.06e+08: mu = 1.00    eta2 = 5.98 +/- 5.62    B0 = 674.95 +/- 158.15
    Shock velocity = 4.67e+08: mu = 1.00    eta2 = 7.92 +/- 7.44    B0 = 741.34 +/- 173.71
    Shock velocity = 5.30e+08: mu = 1.00    eta2 = 10.19 +/- 9.57   B0 = 806.21 +/- 188.91

    Now investigating remnant distance effect
    Dremnant = 2.3 (vs = 3.58e8 * d/2.3): mu = 1.00 eta2 = 4.66 +/- 4.37    B0 = 741.34 +/- 173.70
    Dremnant = 3.0 (vs = 3.58e8 * d/2.3): mu = 1.00 eta2 = 7.92 +/- 7.44    B0 = 741.34 +/- 173.71
    Dremnant = 4.0 (vs = 3.58e8 * d/2.3): mu = 1.00 eta2 = 14.08 +/- 13.23  B0 = 741.34 +/- 173.71
    Dremnant = 5.0 (vs = 3.58e8 * d/2.3): mu = 1.00 eta2 = 22.00 +/- 20.67  B0 = 741.34 +/- 173.71

vs = 2.5e8 corresponds to min of Brian's values.
the remainder: 4.06e8 to 5.3e8, correspond to min/mean/max of the fast velocs
reported, at D= 3 kpc (rather than 2.3 kpc)



Remarks on how to deal with rminarc bug
---------
1. call the code with random values of rminarc
2. check the input parameters in fortran version of code (test/a.out, for now)
and ensure that you get decent numbers there...., if that doesn't help.


Weird bug -- width\_dump with initial guess value is not working -- this is
super important because for Tycho we need to larger B0 values, so the simple
model should help us get there...


TODO CHECK dy values in grid stepping... don't work well for small numbers?
Oh, it's because I force it to step no more than 10 muG at a time...
Updated to step 15 percent of initial B0 value.

Resolution errors are killing the grid stepping !!!!!
I'm seeing both box length errors at 0.7-1kev and resolution errors at 4.5-7 kev
Well, resolution errors don't kill, they just warn.  But box length, now that
kills...

Eventually the whole damn thing just gets stuck when it tries to fill in the
gaps.  I don't mind that some values are bad (though I'd prefer not -- my ad
hoc gridding method doesn't set hard limits on FWHM values right now, it would
be challenging to do so -- remember my functions depend on monotonicity to work
properly).

Ah, I see -- part of the challenge is that we're working with 5 energy bands in
Tycho.  The range of min/max FWHM, regardless of energy, is order 5-10x... in
SN1006 it was up to 7x ish... okay that's not that bad.  But, I think
importantly, in the actual code values we are seeing a bigger range (e.g., 3 to
12 arcsec), vs. SN1006 we would never hit a range that big.

possible solutions?

1. adaptive rminarc (no no can't do this because of bug)
2. use different rminarc values for different energy bands?...
   kind of a pain, but actually not so hard!  Simply call
   generate tables for different energy bands, separately...

   good because it would also improve resolution.

   But, bad because that means we need to stitch the tables together, and they
   won't have the same grids in B0...

3. temporary solution -- use a LARGER max range of FWHMs... (not min range)
   also, I need to twiddle the minimum step size thing...
   Ad hoc solution, always commit before you prepare to run a table and leave
   for the night or w/e.

   Problem... doesn't address resolution errors



When running code, please always make sure it writes to file safely at least 1x
Warning: if changing `f_B0_step` it cannot be too big or you will rapidly hit
resolution errors and the like...

Stupid ad hoc workaround for dynamic rminarc computation:
generate a list of acceptable values, by hand..........
then feed into program to take the appropriate value, dynamically
(using the approach before -- let rscale keep the previous value, but reset it
when we start the next "chain" of B0 computations...)

Dammit I can't afford to mess up my sleep schedule.  I'll go home, sleep, and
come back first thing in the morning, this really needs my time and attention
to address the resolution thing.   The most sustainable solution is to vary
rminarc dynamically.

But, the plan is to just compute grid for one good value of shock veloc just
for now... can do more later.

Monday 2014 July 28
===================





Brian's explanation of the thermal electrons (typically keV), remember you're
looking at log scale stuff.  Thermal all up front, then power law in the back
is what gives us the synchrotron emission.  Tycho is actually kinda unique in
not having so much thermal stuff at the shocks.  And, it seems like SNRs are
very variable in acceleration efficiency -- some you just don't see the x-ray
emissions.

Mentioned effect of changing shock velocity + remnant distance (argh forgot to
bring up numbers for compression ratio as well, oh well. deal with that all
soon).  So yeah definitely need to try it out, get numebrs.

Check SN 1006 data asap to confirm whether 100 eta2 values is enough, or too
much.

For Tycho, definitely account for velocity.
Code -- Brian says, yeah, we have the data, no reason not to make use of the
shock velocities (just got new radio data + Chandra observations in November
2014 too! so we may even use better velocities then).  How long does it take?

18 hours for one run (6 mu, 100 eta2, 20+ (~30?) B0, 3 energy bands), scale up
to 30 hours for Tycho (5 bands instead of 3).  Multiply by ~4x for shock
velocity distribution.

Brian's suggestion -- ad hoc parallelization, just copy the code with several
different parameters and run multiple jobs on same computer, to ensure you are
using multiple processors.

Affirmative, it works very nicely.  Cuts down job time by 1/3rd.


Adding poster images: generated new indiv-band mosaics (recolor 4-7 keV, run
merge\_obs to create 1.7-2.5 keV).  Regenerated all-region plot with scalebar,
larger fonts/widths, preserve original image resolution.


Tuesday 2014 July 29
====================

Summary
-------


Poster plots
------------
Regenerated plots of Region 1 profiles and spectra (from regions-4, plots
generated by `plotter_prfs_specs.ipynb` still, ugly as it is).  Just changed
plot dimensions slightly.

Generated quick plot of average fwhms with a simple model fit; the plot and
code are with the poster files (not elsewhere reproduced).  I did not change
the figure size, just the "standard" one-column sizing.  I think it works okay
so long as it's scaled up/down in Illustrator accordingly.

Model gridding - resolution
---------------------------
On Friday/Saturday we left off at the resolution issue - attempts to grid FWHMs
with Tycho energy bands (and physical parameters) ran into box length bugs or
resolution bugs.  Recall that we are working around / ignoring the mysterious
floating-point? bug for now.

1. Same rminarc for all energy bands, modify Sean's code to take array of
   rminarc values, or 
* 



Plan of attack below.

* Add safeguard to function `f_rscale` in `models_all.py`; have Sean's code
  return _consistent_ nonsense values (e.g., rminarc or 0) for box length and
  resolution errors. Current return values are not obviously incorrect if
  rminarc is comparable to shock radius rsarc, or if we have resolution error.
  (make sure safeguard prints WARNING or ERROR so we can search logs)

* Edit Sean's code to accept an array of rminarc values (this may muck up some
  old methods).  This offers a quick salve to reduce possible rminarc errors,
  both "resolution" and "box length".

* Add an array of "accepted" rminarc values, that don't give strange errors.
  This is a huge problem if we are dynamically updating rminarc -- risk of
  hitting this error is very dangerous, esp. because the safeguards may move
  the wrong way!  Error message/return does not tell us whether it's a real
  resolution/box error, or floating point error.

* At every calculation, compute FWHM values from simple model (should take
  negligible time).  Use minimum of (simple fwhms) x (safety factor) and
  current rminarc, in each band.  KEY ASSUMPTION is that simple model always
  overpredicts fwhm values for given set of (mu, eta2, B0) compared to full
  model.  Just from looking at some numbers, no real justification for this.
  Does this intuitively make sense?  Not obvious that it should always hold,
  since source/sink terms in full model depend on energy, B field, etc...

* Alternately (or alongside simple model), dynamically update rminarc
  based on previous computation's FWHMs (depends on whether B0 is higher or
  lower, now -- or just give enough threshold in either direction?!).
  In either case, need to map
  min( previous fwhm, simple model fwhm, preset constant rminarc ) onto the
  nearest "accepted" rminarc value larger than the obtained min...


Dynamic update seems kind of risky, and very messy, even with simple model +
accepted values only.  Maybe start by adding safeguard + rminarc vector alone,
and see if that will suffice.  Safeguard correcting step (how to step up/down
rminarc) will be yet another twiddle-able knob argh `-_______-`.  But, one good
thing is that if we hit the safeguard issue -- we can make the correction ONLY
in the band where correction is needed, + shrink fit domain in all "okay" bands
to improve the fwhm value slightly while we're at it (negligible time cost,
right?)



Possibility:
* precache a set of possible rminarc values (spanning fwhm min/max and then
  some) -- maybe 10x per energy band.  User must be on hand to monitor this
  process and check that values are okay.... (basic assumption: bad rminarc is
  always bad, independent of input parameters.  if this is violated then we're
  in trouble, all we can do is search log for errors and cross fingers)
* At each initialization (fwhms\_init in maketab\_gridB0), use the "default",
  fairly conservative rminarc values.
* Once you have actual fwhms, find the nearest greater precached rminarc values
  and multiply by a safety factor (do this in each energy band, independently).
  Do this every time you compute fwhms (adaptive updating).
* In `mind_the_gaps` (filling in B0 spacing gaps), we repeatedly run up the
  loop, from smallest B0 value to largest B0 value.  So we'd have to manually
  reset rminarc at the beginning of each loop

This is probably preferable to using the simple model, since we don't have a
qualitative / rigorous handle on how the models disagree / how much they
disagree.

Well, first use array of rminarc.  Some chance that will work straight off the
bat.  Then, implement safeguards and edit fortran code accordingly.  Argh,
right, safeguards requires the precached safe values...

Updated `FullEfflength_mod.f` to take array of rminarc values.

Note: mysterious, inconsistent boxlength error sighted with plain gfortran
code.  Not sure how to reproduce.

Testing with calls to `width_cont` alone seems to be more consistent, vs.
wrapper code for table generation.


Attempt to implement a safeguard failed miserably -- I forgot about the issue
that values need to be precached.  Here's a code snippet, since I didn't commit
this version of the code (given that it was so bad... an adaptive domain is not
a bad idea, I think, but I don't know the best way to implement it.

    def f_rscale(grid_B0):
        """Rescale model width function, option for adaptive rminarc setting
        kwargs: passed straight to width_cont(...)
        rminarc_max must be an array"""
        pars.add('B0', value=grid_B0)  # Vary B0, other parameters same

        fwhms = width_cont(pars, kevs, snr, rminarc = rminarc)
        print '\tModel fwhms = {}'.format(fwhms)

         # Check for box length / resolution errors, and attempt to correct
         # big/small refer to rminarc values
         too_big = fwhms < 1e-8  # Resolution error, rminarc too big
         too_small = fwhms > rminarcs - 1e-8  # Box length, rminarc too small
 
         if any(too_big) or any(too_small):
             # TODO: supposed to be from "safe" precached values
             # Risk of oscillating due to same f_res_adj...
             if any(too_big):
                 print 'Trying to correct resolution error'
                 rminarcs[too_big] = rminarcs[too_big] / f_res_adj
             if any(too_small):  
                 print 'Trying to correct box length error'
                 rminarcs[too_small] = rminarcs[too_small] * f_res_adj
 
             just_right = np.logical_not(np.logical_or(too_big, too_small))
             rminarcs[just_right] = fwhms[just_right] * f_rminarc
             return f_rscale(grid_B0, rminarcs) # Try again
 
         # If no errors, we could try to set widths dynamically

        # Else, return if no errors
        return rscale(fwhms), fwhms



Wednesday 2014 July 30
======================

Summary
-------
* Tweaks to poster (alignment of text/box elements and small updates,
  regenerate 4-7 keV nonthermal emission, print and pin poster in Bldg 28)
* First draft of abstract + revision to Rob/Brian
* Give up on rminarc and configure code set by hand + minor tweaks
* Start generating Tycho grids for 4 shock velocity values
* Cleaned agenda / questions...


Grid generation procedure
-------------------------

Key assumption -- rminarc bug is only for specific rminarc values.  Despite the
cases of the bug appearing or disappearing, when calling identical code 2x
(very frustrating), the hope is that "good" values of rminarc will "stay" good.
This is a gamble.

Procedure for pipeline.
1. Write script to call appropriate method(s) with desired parameters.
2. Determine the "good" values of rminarc.  Take max FWHMs, multiply by safety
   factor, and tweak manually until script doesn't give spurious errors.
3. Run code, checking for box-length and resolution errors in the first call
   with mu = eta2 = 0 (FWHMs vary most drastically without diffusion).
   Continue to update rminarc and `f_B0_step` to avoid such errors.  Note that
   this is separate from the "rminarc bug".

4. Check activity monitor to ensure no processes are hogging CPU. And,
   ensure computer is not allowed to go to sleep (display off only).
5. Call the code as:

    python fullmodel_recompile.py
    git add -A
    git commit
    python one_time_script.py  # Whatever you want to call it

If code is called multiple times (ad hoc parallelization), check for resolution
errors in each individual call.

Note: initial guess for eta2 always fails badly on eta2 = 0, or eta2 extremely
small (`width_dump` function goes singular?).  Not to worry, code will adapt.

6. Search log files for errors (ignore caps)
7. Move tables and log files to /tables and set as read-only
8. Merge tables if needed (not implemented yet)


Tabulating Tycho FWHMs, first attempt
-------------------------------------

I start generating FWHM tables for Tycho using shock velocities
vs = 4.21e8, 4.52e8, 4.83e8, 5.14e8, computed as follows:

Range of velocities above 2500 km/s in Brian's paper is [3110, 4060] km/s.
At d=3kpc, the range becomes 4060 km/s to 5300 km/s.
To span this range evenly with 4 values, take shock velocities of:

    f = np.array([1., 3., 5., 7.]) / 8
    v = 3110 + f * (4060 - 3110)
    v_rescale = v * 3. / 2.3  # For 3 kpc instead of 2.3 kpc

Time: 18 hours for grid of (6, 100, 20+) (mu, eta2, B0), 3 energies for SN 1006
(single core). I expect 30 hrs x 4/3 for Tycho as 4 cores gave 3x speedup in an
ad hoc test with SN1006 numbers, from earlier this week.

Expect to finish: about 12:30pm on Friday, August 1.

Goal is to have code to check gridding and compute best fits from table values
ready by Friday.  Then I can rerun grid over weekend if needed.

Started around 8:30pm, Wednesday July 30


Thursday 2014 July 31
=====================

Poster session...
More skeleton code / messing with grid fit / simple fit prettyprinting etc.


Friday 2014 August 01
=====================

Summary
-------
* Troubleshoot box length errors and resumed gridding for Tycho's SNR


Failed gridding troubleshooting
-------------------------------

Found that gridding was hanging up this morning.  Stopped and recorded error
output printed to screen.  It turns out that my Python stdout logging does NOT
capture "Box Length Error ..." printouts from f2py-compiled module!

### When did gridding fail?
Pkl files were last written 03:10 -- 03:16, August 1st.

### Are previous values okay?
Yes, in principle pkl has only stored "good" values (when a resolution or box
length error occurs, the code hangs indefinitely (empirically...) trying to
interpolate the FWHM gaps).

Since logs don't record f2py error messages (I amend `models_all.py` to rectify
this...), find errors in TextMate or other editor with decent search/replace:
* box length errors: search for "240.", or regex search for
  `Model fwhms = \[.* 240\..*\]`
* resolution errors: regex search for `Model fwhms = \[.* 0\.0.*\]`

Search for previous errors turned up nothing, so older data should be good.

### What happened?
Computing FWHMs at values below initial B0 (wider rims), rminarc was too small.
When diffusion is large (eta2 large), rims at high energies are wide; the most
extreme case of (mu, eta2) = (2, 100) WIDENS rims at increasing energy.

Since we lost about 7.5 hours, I expect this gridding to finish around 7pm
tonight.

### New procedure
Always test rminarc values with cases (mu, eta2) = (0., 0.) AND (mu, eta2) =
(2., 100.), or whatever the maximum values of mu, eta2 are for your grid.

* No diffusion gives max FWHM spread, check for box length errors at lowest
  energy, resolution errors at highest energy
* Max diffusion gives min FWHM spread, check for box length errors at highest
  energy, resolution errors at lowest energy

We want smallest rminarc values we can get away with.  Errors are also set by
minimum/maximum FWHM values to table.  Bit of a balancing act, to get enough
data but also avoid box / resolution errors.

I restart gridding from (mu, eta2) = (1.5, 15.26) and generate two more sets
of grid files, to be merged with the larger ("part one") output.  Note that the
grid on (mu, eta2) = (1.5, 15.26) is repeated for vs = 5.14e8.

### Error logs for reference

These are copy-pasted from terminal output, since error notifications weren't
saved to log files.

#### vs = 4.21e8

    (mu, eta2) = (1.50, 15.26)
    ---------------------------------
    Checking initial guess for B0
        Function call with B0 = 458.987 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 3.05  2.89  2.67  2.55  2.46]
    Initial guess accepted
    Using initial B0 value 458.986958344 muG
    Now finding B0 values with FWHMs in range.
    Require 4 values above, 16 below initial B0
    Computing values below initial B0
        Function call with B0 = 463.577 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 3.01  2.85  2.61  2.52  2.43]
        ...
        ...
        Function call with B0 = 202.174 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
            Model fwhms = [ 10.68  10.05   9.18   8.83   8.53]
            Function call with B0 = 196.178 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
         Box Length Error (xmin) at   4.5000000000000000     
            Model fwhms = [  11.19   10.5     9.61    9.24  240.  ]



#### vs = 4.52e8

    (mu, eta2) = (1.50, 15.26)
    ---------------------------------
    Checking initial guess for B0
        Function call with B0 = 462.406 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 3.15  2.96  2.72  2.58  2.48]
    Initial guess accepted
    Using initial B0 value 462.405952043 muG
    Now finding B0 values with FWHMs in range.
    Require 4 values above, 16 below initial B0
    Computing values below initial B0
        Function call with B0 = 467.030 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 3.1   2.93  2.67  2.55  2.46]
        ...
        ...
        Function call with B0 = 205.228 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
            Model fwhms = [ 10.82  10.13   9.24   8.86   8.53]
            Function call with B0 = 199.174 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
         Box Length Error (xmin) at   4.5000000000000000     
            Model fwhms = [  11.33   10.61    9.67    9.27  240.  ]



#### vs = 4.83e8

    (mu, eta2) = (1.50, 15.26)
    ---------------------------------
    Checking initial guess for B0
        Function call with B0 = 465.863 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 3.24  3.04  2.75  2.61  2.53]
    Initial guess accepted
    Using initial B0 value 465.863155822 muG
    Now finding B0 values with FWHMs in range.
    Require 4 values above, 16 below initial B0
        ...
        ...
    Function call with B0 = 208.638 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 10.92  10.2    9.24   8.83   8.51]
        Function call with B0 = 202.435 muG; eta2 = 15.264; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
     Box Length Error (xmin) at   4.5000000000000000     
        Model fwhms = [  11.47   10.69    9.67    9.27  240.  ]



#### vs = 5.14e8

This one barely made it past the eta2 = 15.26 stumbling block...

    (mu, eta2) = (1.50, 22.23)
    ---------------------------------
    Checking initial guess for B0
        Function call with B0 = 520.874 muG; eta2 = 22.230; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 3.1   2.93  2.67  2.55  2.46]
        ...
        ...
    Function call with B0 = 229.784 muG; eta2 = 22.230; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
        Model fwhms = [ 10.68  10.05   9.18   8.83   8.53]
        Function call with B0 = 222.784 muG; eta2 = 22.230; mu = 1.500; rminarc = [18.5, 15.0, 10.77, 11.73, 9.1]
     Box Length Error (xmin) at   4.5000000000000000     
        Model fwhms = [  11.19   10.54    9.64    9.24  240.  ]


Gridding fits and things
------------------------

CONTINUING... (see agenda.md)

To determine 90% confidence interval errors: `lmfit.conf_interval` has
difficulty stepping eta2 up/down, especially when eta2 is near zero.
Example output from SN 1006, Filament 3 (this required up to 3000 iterations):

    [[Variables]]
         B0:       8.066719e-05 +/- 2.606319e-06 (3.23%) initial =  0.00015
         eta2:     0.0001000048 +/- 0.1367508 (136744.26%) initial =  1
         mu:       1 (fixed)
    [[Correlations]] (unreported correlations are <  0.100)
        C(B0, eta2)                  =  0.936 
            90.00%     0.00%    90.00%
      B0   0.00008   0.00008   0.00011
    eta2      -inf   0.00010   2.87972


...
(add more notes later)
Finished building and mostly(?) debugging rootfinder to find confidence
interval limits for simple model fits.  Tursn out that lmfit uses an F-test of
some kind, very different approach.

Ran fits from best grid values, as I think I did try before.  Yup, it's a mess.
So we're gonna need a systematic way to tackle this...


Sunday 2014 August 3
====================

Error code for full model fit (working off of grid, then attempting to throw in
fits where reasonable).  Generating lots of output to compare...
And, check chisqr values from Sean's paper to ensure we are doing okay?...


To discuss on Monday -- further work after this week?, going through code with
Rob/Brian, explanation of my error calculations (and perhaps, summarize what
I've been doing... -- and the meaning of all the tables/plots)

Summary of results from error "annealing"

    Filament 1, best grid pt: eta2 = 2.857, B0 = 102.98
        naive grid bounds (eta2): 0.9103, 8.3673
        naive grid bounds (B0): 93.0410, 121.9826

        final grid bounds (eta2): 0.8163, 8.9796
        final grid bounds (B0): 92.9694, 121.9624


    Filament 2, best grid pt: eta2 = 0.202, B0 = 130.01
        naive grid bounds (eta2): 0.1677, 0.2041
        naive grid bounds (B0): 127.7476, 129.7336

        final grid bounds (eta2): 0.1677, 0.2041
        final grid bounds (B0): 130.7659, 130.0812


    Filament 3, best grid pt: eta2= 0.054, B0 = 73.76
        naive grid bounds (eta2): 0.0000, 0.1389
        naive grid bounds (B0): 74.2814, 73.2134

        final grid bounds (eta2): 0.0000, 0.2442
        final grid bounds (B0): 74.2814, 74.4371


    Filament 4, best grid pt: eta2 = 0.026, B0 = 106.93
        naive grid bounds (eta2): 0.0000, 0.0954
        naive grid bounds (B0): 110.0000, 109.1598

        final grid bounds (eta2): 0.0000, 0.2442
        final grid bounds (B0): 110.0000, 108.2212


    Filament 5, best grid pt: eta2 = 82.864, B0 = 208.82
        naive grid bounds (eta2): 12.6486, 100.0000
        naive grid bounds (B0): 139.4589, 214.5354

        final grid bounds (eta2): 10.4811, 100.0000
        final grid bounds (B0): 137.1678, 214.5354


Monday 2014 August 4
====================

Summary
-------
* lalala
* Tabulated a bunch of results, checking effects of error computation, fitting
  on grid, comparison to Sean's best fit parameters.
* Large code restructuring (shift from ipynb to python module)

Reviewed results.  Possibility -- just fix several values of eta2, depends on
how well constrained it is in Tycho.  Besides, we don't really expect eta2
smaller than 1... sub Bohm diffusion?!?!?!  Bother Steve Reynolds in Moscow.


Nailing down grid fits
----------------------
Want to get a handle on both parameter values + errors.



Spline fitting in B0-chisqr space -- looks okay.  About half the time, it
doesn't get a better value.
Try a polynomial fit as well.  Yup, looks about the same.

Also, this actually isn't that useful because... we can't use the chisqr values
we get out usually -- esp. when chisqr shoots negative!...
what if we try a strictly interpolating spline?  still a risk of
overshooting... just another source of noise.  If we want to nail down chisqr
space we'd have to perform the actual computation.

If we try to fit, we won't have the same rminarc values, which adds
fluctuation too...
best verdict.  Forget it.  Only worry about fitting at best fit and error
bounds, likely it won't matter within error...

Verdict: don't worry about interpolating.  It's kind of okay.  Let a more
careful fit around best grid values help figure out best parameters, and
realize that errors are very large anyways.  We're not doing a lot better than
manual fitting here.

Major code restructuring and cleaning, after seeing that the outputs work and
look okay.  Goal is to clean up the SN 1006 output, then prepare to run it on
Tycho.

A little less done today, w/ morning meeting + afternoon meeting + a little bit
of planning time.  But a lot of code clean up, things look a little more
manageable.


Tuesday 2014 August 5
=====================

Finished cleaning/porting code, testing and debugging.  It looks like
lmfit.minimize goes bonkers when I feed in an rminarc array (to try to
slightly improve resolution).

AHA, I see errors are popping up in the ipython notebook log...
bad rminarc values seem to induce the error, though I have
difficulty reproducing the error when calling the function outside of lmfit.
waaaaaaaaaaa

Verdict: keep rminarc fixed for each remnant, at a value (or set of values)
that seems to work.  Get some numbers, messy as they will be.
Reimplement the code in python and aim for speedup and better resolution.
the rminarc bugs and things are getting to be too much.

The weird thing is that, when doing the grid tabulation, lmfit isn't even
involved.  But, qualitatively, the bugs seem more likely, or kind of on and
off, when lmfit.minimize calls the function........

Discussion w/ Brian in re optimizing the intensity profile calculations
(compute only where necessary to constrain FWHM, and get higher accuracy).


This whole procedure of trying to fit within the grid, and annealing errors, is
somewhat suspect but we should at least make the systematic attempt.
Then, with data in hand, we can:
1. go ahead with the python improvement and maybe we can improve resolution,
   get closer to machine precision
2. say the error is so large anyways, that although our method and numbers are
   imperfect it likely doesn't matter.

But we need tycho numbers first before we can make any, any assessments!

Merged Tycho tables together, by hand essentially (short one-off script).

Started Tycho notebook


Wednesday 2014 August 6
=======================

Start some skeleton code for Fortran port.  I think we can get a good speed up
by pre-tabulating the emissivity as a function of radius, and interpolating its
value when integrating over line of sight.  So we tabulate the distributions,
and then at each radial coordinate we only need ONE integral to get intensity!


Tycho fits and numbers generated.
Run by Brian -- he and Rob will see Steve at HEAD meeting (Steve at conference
is generally not so responsive, being without smartphone and busy).
We really need to nail down chi-squared space.  Time for a rewrite.

More code for Fortran port -- FWHM calculation (now using sign crossings),
flesh out main method (copied over all electron distribution functions).


Thursday 2014 August 7
======================

Continue Fortran code port.  Some timings, now (for ONE energy band)

1st iteration:
* spint for e- tables: 1 second.
* manual, pt by pt loop for emisx, intensity: 3 minutes (!!!)

2nd iteration:
* spint for e- tables: 1.3 sec (to be more precise)
* manual loop for intensity, spint for emissivity: 1.5 minutes (!!)

3rd iteration:
* manual loop for intensity, read fglists only 1x, spint for emissivity: 19 sec.
  (cutting repeated file reads dropped times by like 5x)

4th iteration (good reference):
* spint for e- tables: 1.3 sec
* map emisx (spint) table: 0.2 sec
* manual loop for intensity, interpolate emis from table: 2.2 seconds
  (interpolate emis vs. integrating cut times ~10x !!)

Bulk timing: Python is ~11.2 seconds, Fortran (shell timing) is 3.3 seconds.
But, fortran isn't interpolating for emissivity and would benefit greatly from
that speedup too.

Quick check, gfortran with `-O3` flag: Fortran w/ shell timing is 2.1 seconds.
Goddddddaaaammit.

5th iteration:
* spint for e- tables: 1.3 sec
* map emisx (spint) table: 0.2 sec
* manual loop for intensity, interp emis w/single call: 0.15 seconds
  (single vectorized call to `interp_ind` instead of loop)

Cut from 11 sec to 5 sec, and cut intensity computation by 10x!  Beautiful

6th iteration:
* spint for e- tables using 3-d arrays (grid on radtab, e- energy): 0.75 sec

Cut to 3.2 sec.  So by careful memory management w/ e- tab, we cut that time in
about 1/2.


Some conclusions:
1. program smart
2. when compiling f2py module, always use -O3 flag!
3. table interpolating is huge for speedup.  I wonder where the time is going
   into w/ the e- table calculations (can we speed that up)
4. do we need cython or something to further improve python code, now.
5. adaptive intensity calculation, now, if possible (w/ binary like search).
   But that may be slow to implement in Python -- but still probably faster
   than all the redundant calls to trapz


Try playing with python-latex output
http://code.google.com/p/matrix2latex/


