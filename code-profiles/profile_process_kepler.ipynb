{
 "metadata": {
  "name": "",
  "signature": "sha256:4467e81b810e3c537cf80c8418d8706ebdc18e7057811263f2666b241d883989"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "0. Profile fits and stuff"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aaron Tran, summer 2014.<br>\n",
      "Mentors: Rob Petre, Brian J. Williams.\n",
      "\n",
      "This iPython notebook performs the following tasks:\n",
      "* Fit radial intensity profiles of thin synchrotron rims in supernova remnants (just Tycho's SNR for now).\n",
      "* Calculate rim FWHM's and uncertainties from fit functions.\n",
      "* Estimate the energy dependence of rim widths to constrain magnetic field amplification / electron diffusion processes occuring in SNR shocks.\n",
      "\n",
      "Currently, sections 2,3 are good candidates for moving to separate python modules.  But that's slightly lower priority, right now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%pylab --no-import-all\n",
      "%matplotlib inline\n",
      "# ('gtk', 'inline', 'osx', 'qt', 'qt4', 'tk', 'wx')\n",
      "from fplot import fplot, show_mplrc_settings\n",
      "\n",
      "import cPickle as pickle\n",
      "import datetime\n",
      "import inspect\n",
      "import os\n",
      "import re\n",
      "import scipy as sp\n",
      "from scipy import interpolate\n",
      "from scipy import optimize\n",
      "from scipy import signal\n",
      "\n",
      "import regparse  # My own utility methods for region file parsing\n",
      "import fit_funcs as ff  # Profile fitting functions\n",
      "import fsmooth as fsmth  # Homebrewed smoothing functions\n",
      "import crvfit  # Homebrewed wrapper for sp.optimize.curve_fit, allows parameter freezing\n",
      "import ffwhm  # FWHM calculation, error finding (stretching)\n",
      "\n",
      "# For nose tests in iPython\n",
      "%load_ext ipython_nose\n",
      "\n",
      "# For reference\n",
      "show_mplrc_settings()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. Profile fitting procedure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: the code is not well-designed.  It would benefit from modularization, maybe further refactoring, as this notebook is getting long and unwieldy.  But, it works for now.\n",
      "\n",
      "Some possibly useful SciPy cookbooks:\n",
      "* [wiki.scipy.org/Cookbook/FittingData](http://wiki.scipy.org/Cookbook/FittingData).\n",
      "* [wiki.scipy.org/Cookbook/SignalSmooth](http://wiki.scipy.org/Cookbook/SignalSmooth)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1.3 Fit routines for each profile fitting function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately it's a bit repetitive -- but I think this is as deep as I can refactor for now, because the rest needs hand-tweaking...\n",
      "\n",
      "In each of these fit methods there's a ton of twiddle-able numbers -- initial guesses for parameters, where to freeze/thaw parameters, etc."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.3.3 Two exponential model, simplified (split located at $x_0$)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def fit_2exp_simp(x, y, y_err):\n",
      "    \"\"\"FIT THE PROFILE\"\"\"\n",
      "    \n",
      "    # Call signature: ff.two_exp_simp(x, x0, Cu, Cd, wu, wd, Au)\n",
      "    f = ff.two_exp_simp\n",
      "    \n",
      "    pars = ['x0', 'Cu', 'Cd', 'wu', 'wd', 'Au']\n",
      "    prnt_pars = [par + ' = {:5.4g}, ' for par in pars]\n",
      "    prnt_pars = ''.join(prnt_pars)[:-2]  # Cut trailing comma, space\n",
      "    \n",
      "\n",
      "    #################\n",
      "    # Initial guesses\n",
      "    #################\n",
      "    \n",
      "    # Freeze: x0\n",
      "    x0 = x[np.argmax(y)]\n",
      "    # Free parameters: Cu, Cd, wu, wd, Au\n",
      "    Cu = np.mean(y[-3:])  # The obvious guess\n",
      "    Cd = np.mean(y[:3]) / 3.  # Usually shoots under trough\n",
      "    wu = 0.5  # Upstream width\n",
      "    wd = 2.5  # Downstream width\n",
      "    Au = np.amax(y)/3.  # Upstream amplitude\n",
      "    \n",
      "    init_guess = [x0, Cu, Cd, wu, wd, Au]\n",
      "    print ('Initial guesses: ' + prnt_pars).format(*init_guess)\n",
      "    \n",
      "    ###################\n",
      "    # First fit attempt\n",
      "    ###################\n",
      "    \n",
      "    frz = [0]\n",
      "    popt, pcov, popt_all = crvfit.run_frz_fit(x, y, y_err, f, init_guess, frz)\n",
      "    print ('Fit (x0 frozen): ' + prnt_pars).format(*popt_all)\n",
      "    \n",
      "    ####################\n",
      "    # Second fit attempt\n",
      "    ####################\n",
      "    \n",
      "    # Unfreeze: xs, x0; all parameters free\n",
      "    init_guess = popt_all\n",
      "    popt, pcov = crvfit.run_fit(x, y, y_err, f, init_guess)\n",
      "    print ('Fit (x0 thawed): ' + prnt_pars).format(*popt)\n",
      "    \n",
      "    #######################\n",
      "    # Print fit information\n",
      "    #######################\n",
      "    \n",
      "    crvfit.print_fit_info(x, y, y_err, f, popt, pcov)\n",
      "    \n",
      "    return popt, pcov, f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.3.4 Two exponential function, simplified ($x_s = x_0$), with manual cap imposed on function height..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall that the function is:\n",
      "\n",
      "\\begin{align*}\n",
      "    h_{\\mathrm{up}}(x) &= A_u \\exp \\left(\\frac{x_0-x}{w_u}\\right) + C_u \\\\\n",
      "    h_{\\mathrm{down}}(x) &= A_d \\exp \\left(\\frac{x - x_0}{w_d}\\right) + C_d\n",
      "\\end{align*}\n",
      "\n",
      "Therefore, we demand that $h(x_0) = A_u + C_u = A_d + C_d$ be less than some cap.  If the sum $A_u + C_u$ is greater than this cap, then the function explodes everywhere.  So this sets a wall, essentially (though I think the function will tend to fit at the wall, if it wants to creep to steeper exponentials."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def fit_2exp_simp_cap(x, y, y_err, hcap):\n",
      "    \"\"\"FIT THE PROFILE\n",
      "    hcap indicates the fraction of the maximum data value\n",
      "    at which to limit the function\n",
      "    \"\"\"\n",
      "    \n",
      "    # Very ad hoc way to impose height limit\n",
      "    def func_capped(x, x0,Cu,Cd,wu,wd,Au):\n",
      "        def f_help(x, x0,Cu,Cd,wu,wd,Au):\n",
      "            if Au+Cu > hcap * np.amax(y):\n",
      "                return 1e20\n",
      "            return ff.two_exp_simp(x, x0,Cu,Cd,wu,wd,Au)\n",
      "        f_vec = np.vectorize(f_help)\n",
      "        return f_vec(x, x0,Cu,Cd,wu,wd,Au)\n",
      "    \n",
      "    # Call signature: two_exp_function_simp(x, x0, Cu, Cd, wu, wd, Au)\n",
      "    f = func_capped\n",
      "    \n",
      "    pars = ['x0', 'Cu', 'Cd', 'wu', 'wd', 'Au']\n",
      "    prnt_pars = [par + ' = {:5.4g}, ' for par in pars]\n",
      "    prnt_pars = ''.join(prnt_pars)[:-2]  # Cut trailing comma, space\n",
      "\n",
      "    #################\n",
      "    # Initial guesses\n",
      "    #################\n",
      "    \n",
      "    # Freeze: x0\n",
      "    x0 = x[np.argmax(y)]\n",
      "    # Free parameters: Cu, Cd, wu, wd, Au\n",
      "    Cu = np.mean(y[-3:])  # The obvious guess\n",
      "    Cd = np.mean(y[:3]) / 3.  # Usually shoots under trough\n",
      "    wu = 0.5  # Upstream width\n",
      "    wd = 2.5  # Downstream width\n",
      "    Au = np.amax(y)/3.  # Upstream amplitude\n",
      "    \n",
      "    init_guess = [x0, Cu, Cd, wu, wd, Au]\n",
      "    print ('Initial guesses: ' + prnt_pars).format(*init_guess)\n",
      "    \n",
      "    ###################\n",
      "    # First fit attempt\n",
      "    ###################\n",
      "    \n",
      "    frz = [0]\n",
      "    popt, pcov, popt_all = crvfit.run_frz_fit(x, y, y_err, f, init_guess, frz)\n",
      "    print ('Fit (x0 frozen): ' + prnt_pars).format(*popt_all)\n",
      "    \n",
      "    ####################\n",
      "    # Second fit attempt\n",
      "    ####################\n",
      "    \n",
      "    # Unfreeze: xs, x0; all parameters free\n",
      "    init_guess = popt_all\n",
      "    popt, pcov = crvfit.run_fit(x, y, y_err, f, init_guess)\n",
      "    print ('Fit (x0 thawed): ' + prnt_pars).format(*popt)\n",
      "    \n",
      "    #######################\n",
      "    # Print fit information\n",
      "    #######################\n",
      "    \n",
      "    crvfit.print_fit_info(x, y, y_err, f, popt, pcov)\n",
      "    \n",
      "    return popt, pcov, f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.3.7 Smoothed interpolating spline \"fit\" (not really)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def fit_spline(x, y, y_err, sfactor=0.05):\n",
      "    \"\"\"Smoothed spline fit, with weights = 1./y_err\n",
      "    Twiddle sfactor to vary amt of smoothing\n",
      "    \"\"\"\n",
      "    splfit = sp.interpolate.UnivariateSpline(x, y, w=1./y_err, s=sfactor*len(y))  # Default s=len(w)\n",
      "    # popt = []  # Unpacks safely with *popt \n",
      "    # pcov = None\n",
      "    # return popt, pcov, splfit\n",
      "    return splfit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3. Main methods"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.1 Set-up: build initial data structure for regions and energy bands"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data values, uncertainties, etc. are imported/calculated here.  E.g., to use total counts, average counts, intensity flux, change code here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def init_region_dict(ds9physreg, inroot, ctroot, labels, px2arcsec):\n",
      "    \"\"\"Initialize region dictionary to store region/energy band data/info\n",
      "    \n",
      "    Add data with errorbars, region information (dimensions).\n",
      "    \n",
      "    Inputs: filenames (strings)\n",
      "        ds9physreg\n",
      "        inroot: intensity data file root (from ds9projplotter.py)\n",
      "        ctroot: count data file root (from ds9projplotter.py)\n",
      "        labels: energy band labels\n",
      "        px2arcsec: conversion factor from physical units (pixels) to arcseconds\n",
      "    \n",
      "    Output: dictionary, keyed by region number (values are more dictionaries)\n",
      "    \"\"\"\n",
      "    \n",
      "    def get_proj_dims(regstrs):\n",
      "        \"\"\"Get projection dimensions from list of regions, must all be projections\n",
      "        \n",
      "        Input: list of region strings\n",
      "        Output: list of 2-tuples, of length (radial dist.)\n",
      "            and thickness (integration length), both in pixels\n",
      "        \"\"\"\n",
      "        dims = []\n",
      "        for line in regstrs:\n",
      "            rtype, rnums, rprops = regparse.regparse(line)\n",
      "            if 'projection' not in rtype:\n",
      "                raise Exception('Projection region expected; region type was {}'.format(rtype))\n",
      "            x1,y1,x2,y2,w = rnums\n",
      "            length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
      "            dims.append((length, w))\n",
      "        return dims\n",
      "    \n",
      "    dims = get_proj_dims(regparse.load_ds9reg(ds9physreg))\n",
      "    regions = {}\n",
      "    \n",
      "    for i in xrange(len(dims)):\n",
      "        \n",
      "        reg = regions[i+1] = {}\n",
      "        reg['info'] = {}\n",
      "        reg['info']['length'], reg['info']['thickness'] = dims[i]  # Units: physical pixels\n",
      "        reg['info']['px2arcsec'] = px2arcsec\n",
      "        \n",
      "        print 'R{:02d} length (px): {: 0.2f}, thickness (px): {: 0.2f}'.format(i+1, *dims[i])\n",
      "\n",
      "        for lab in labels:\n",
      "\n",
      "            # Set up each energy band's dictionary\n",
      "            reg[lab] = {}\n",
      "\n",
      "            # Intensity data\n",
      "            infile = '{0}_{1:02d}_band_{2}.dat'.format(inroot, i+1, lab)\n",
      "            data = np.loadtxt(infile)\n",
      "            x = (data[:,0] - 1) * px2arcsec  # Convert to arcsec, with x[0] = 0\n",
      "            y = data[:,1]\n",
      "            \n",
      "            # Count data\n",
      "            ctfile = '{0}_{1:02d}_band_{2}.dat'.format(ctroot, i+1, lab)\n",
      "            thck = np.floor(reg['info']['thickness'])  # MUST FLOOR to be consistent w/ DS9, for number of pixels integrated\n",
      "            data_cts = np.loadtxt(ctfile)\n",
      "            cts = data_cts[:,1]  # Counts already averaged over region thickness\n",
      "            cts_err = np.sqrt(cts * thck) / thck\n",
      "            cts_err[cts_err==0] = np.sqrt(1) / thck  # Give 0 cts the error for 1 ct\n",
      "            \n",
      "            # Use count data to compute y errors\n",
      "            y_err = cts_err / cts * y\n",
      "            # Edge cases -- if cts=0, or y=0 (since cts_err is always nonzero)\n",
      "            y_err[cts==0] = y[cts==0]  # If cts==0, use y value: same as 1 +/- 1 for Poisson error            \n",
      "            y_err[y_err==0] = np.amin(y_err[np.nonzero(y_err)])  # If y=0 (even if cts!=0), use min non-zero error\n",
      "\n",
      "            # Save to energy band dictionary\n",
      "            reg[lab]['data'] = x, y, y_err\n",
      "    \n",
      "    return regions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def add_cut_data(regdict, wlen, wtype):\n",
      "    \"\"\"Apply fit domain cut over each region, each energy band; store in region dict\n",
      "    \n",
      "    Input:\n",
      "        wlen: window length for smoothing to identify fit domain cut-off\n",
      "        wtype: window type for smoothing, as above\n",
      "    \"\"\"\n",
      "    \n",
      "    for n in regdict:\n",
      "        reg = regdict[n]\n",
      "        for lab in reg:\n",
      "            if lab == 'info':\n",
      "                continue\n",
      "                \n",
      "            x, y, y_err = reg[lab]['data']\n",
      "            \n",
      "            cut = fsmth.ind_first_min(y, window_len=wlen, window=wtype)\n",
      "            reg[lab]['cut'] = cut\n",
      "            reg[lab]['data-fit'] = x[cut:], y[cut:], y_err[cut:]\n",
      "    \n",
      "    return regdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.2 Perform profile fits, calculate FWHMs, spew information into region dict"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The truth is that, dammit, it's really convenient to have fit output + numbers + plots all together in one place.  It makes debugging / validation a lot easier.  So I give up...\n",
      "\n",
      "Here, set what function you use to fit the profiles, what other functions to try, what information to store in the region dictionary -- decide what you want and stuff it in here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def fill_region_dict(reg, wlen, wtype, dx, xconst, blist):\n",
      "    \"\"\"reg should be an input region dictionary, to be filled with data -- FWHMs and other things\n",
      "    Spews out a crapton of information and plots\n",
      "    Relies on several variables in the global namespace -- be careful.\n",
      "    blist = blacklist -- don't attempt to compute FWHM errors for these guys.  AD HOC PATCH UGH.\n",
      "    \"\"\"\n",
      "    \n",
      "    fig1, axes1 = plt.subplots(1, len(labels), figsize=(6*len(labels),5))\n",
      "    fig2, axes2 = plt.subplots(1, len(labels), figsize=(6*len(labels),5))\n",
      "    \n",
      "    for lab, ax1, ax2 in zip(labels, axes1, axes2):\n",
      "        print ''\n",
      "        print '--------------'\n",
      "        print 'Band: {}'.format(lab)\n",
      "        print '--------------'\n",
      "        \n",
      "        x_fit, y_fit, y_err_fit = reg[lab]['data-fit']\n",
      "        \n",
      "        # Identify blacklisted region - energyband combinations, don't compute errors\n",
      "        # in those cases\n",
      "        want_err = False if lab in blist else True\n",
      "        \n",
      "        ###################\n",
      "        # Main fit and FWHM\n",
      "        ###################\n",
      "        \n",
      "        popt, pcov, f = fit_2exp_simp(x_fit, y_fit, y_err_fit)  # DETERMINES FIT FUNCTION / PROCEDURE{}\n",
      "        reg[lab]['f'] = inspect.getsource(f)\n",
      "        reg[lab]['pars'] = popt\n",
      "        reg[lab]['meas'] = {}  # Dictionary for measurements\n",
      "        \n",
      "        # For background subtraction, replace `f` with\n",
      "        # lambda x, *pars: f(x,*pars) - y_bkg\n",
      "        w, lims, errs = ffwhm.get_fwhm_all(x_fit, y_fit, y_err_fit, f, popt, want_err=want_err, y_cap=None, dx=dx, xconst=xconst)\n",
      "        reg[lab]['meas']['fwhm'] = w\n",
      "        reg[lab]['meas']['fwhm-lims'] = lims\n",
      "        reg[lab]['meas']['fwhm-errs'] = errs\n",
      "        \n",
      "        ###########################\n",
      "        # Additional fits and FWHMs\n",
      "        ###########################\n",
      "        \n",
      "        # Capped FWHM for fit function; maximum set to largest data point\n",
      "        w, lims, errs = ffwhm.get_fwhm_all(x_fit, y_fit, y_err_fit, f, popt, want_err=want_err, y_cap=np.amax(y_fit), dx=dx, xconst=xconst)\n",
      "        reg[lab]['meas']['fwhmc'] = w\n",
      "        reg[lab]['meas']['fwhmc-lims'] = lims\n",
      "        reg[lab]['meas']['fwhmc-errs'] = errs\n",
      "        \n",
      "        # FWHM for a spline fit\n",
      "        # Cannot use get_fwhm_all errors\n",
      "        s = fit_spline(x_fit, y_fit, y_err_fit, sfactor=0.05)\n",
      "        w, lims, errs = ffwhm.get_fwhm_all(x_fit, y_fit, y_err_fit, s, [], want_err=want_err, y_cap=None, dx=dx, xconst=xconst)  # Errors are meaningless\n",
      "        reg[lab]['meas']['fwhms'] = w\n",
      "        reg[lab]['meas']['fwhms-lims'] = lims\n",
      "        \n",
      "        # Fit with a CAP on amplitude (fcap)\n",
      "        popt_fitc, pcov_fitc, f_fitc = fit_2exp_simp_cap(x_fit, y_fit, y_err_fit, hcap=1.0)\n",
      "        # Then get FWHM as usual (y_cap=None)\n",
      "        w, lims, errs = ffwhm.get_fwhm_all(x_fit, y_fit, y_err_fit, f_fitc, popt_fitc, want_err=want_err, y_cap=None, dx=dx, xconst=xconst)\n",
      "        reg[lab]['meas']['fwhm_fitc'] = w\n",
      "        reg[lab]['meas']['fwhm_fitc-lims'] = lims\n",
      "        reg[lab]['meas']['fwhm_fitc-errs'] = errs\n",
      "        \n",
      "        ############################\n",
      "        # Plot the data, fits, FWHM,\n",
      "        # and FWHM left/right bounds\n",
      "        ############################\n",
      "        x, y, y_err = reg[lab]['data']\n",
      "        ax1.errorbar(x, y, yerr=y_err, fmt='rx', alpha=0.2)  # All raw data\n",
      "        ax1.plot(x, fsmth.std_smooth(y, wlen, wtype), '-k', alpha = 0.2)  # Show smoothing to set fit domain\n",
      "        ax1.errorbar(x_fit, y_fit, yerr=y_err_fit, fmt='bo', alpha=0.7)  # Show data used in fit\n",
      "\n",
      "        x_m = np.linspace(x_fit[0], x_fit[-1], num=200)  # x values for best fit model\n",
      "        ax1.plot(x_m, f(x_m, *popt), '-k', alpha=1)  # Best fit model\n",
      "\n",
      "        ax1.set_ylim(0., ax1.get_ylim()[1])\n",
      "        ax1.set_xlabel('Radial dist. (arcsec.)')\n",
      "        ax1.set_ylabel('Est. counts ~ intensity')\n",
      "        ax1.set_title(lab)\n",
      "        \n",
      "        ############################\n",
      "        # Plot FWHM bounds near peak\n",
      "        ############################\n",
      "        \n",
      "        ax2.errorbar(x_fit, y_fit, yerr=y_err_fit, fmt='bo', alpha=0.2)  # Data used in fit\n",
      "        ax2.plot(x_m, f(x_m, *popt), '-k', alpha=1)  # Best fit model\n",
      "        ax2.plot(x_m, s(x_m), '-r', alpha=0.6)  # Interpolating spline\n",
      "        \n",
      "        ax2.set_xlim(x_fit[np.argmax(y_fit)]-0.5, x_fit[np.argmax(y_fit)]+0.5)\n",
      "\n",
      "        # Delineate FWHM measurements, if possible\n",
      "        if np.isfinite(reg[lab]['meas']['fwhm']):\n",
      "            a, b = reg[lab]['meas']['fwhm-lims']\n",
      "            ax2.axvline(a, alpha=1, ls='-', c='k', lw=2)\n",
      "            ax2.axvline(b, alpha=1, ls='-', c='k', lw=2)\n",
      "            ax2.set_xlim(min(ax2.get_xlim()[0], a-2),\n",
      "                         max(ax2.get_xlim()[1], b+2))\n",
      "        if np.isfinite(reg[lab]['meas']['fwhmc']):\n",
      "            a, b = reg[lab]['meas']['fwhmc-lims']\n",
      "            ax2.axvline(a, alpha=1, ls='--', c='g', lw=2)\n",
      "            ax2.axvline(b, alpha=1, ls='--', c='g', lw=2)\n",
      "            ax2.set_xlim(min(ax2.get_xlim()[0], a-2),\n",
      "                         max(ax2.get_xlim()[1], b+2))\n",
      "        if np.isfinite(reg[lab]['meas']['fwhms']):\n",
      "            a, b = reg[lab]['meas']['fwhms-lims']\n",
      "            ax2.axvline(a, alpha=1, ls=':', c='r', lw=2)\n",
      "            ax2.axvline(b, alpha=1, ls=':', c='r', lw=2)\n",
      "            ax2.set_xlim(min(ax2.get_xlim()[0], a-2),\n",
      "                         max(ax2.get_xlim()[1], b+2))\n",
      "        \n",
      "        if ax2.get_xlim()[0] == x_fit[np.argmax(y_fit)]-0.5:\n",
      "            ax2.set_xlim(x_fit[0], x_fit[-1])\n",
      "        \n",
      "        ax2.set_ylim(0., ax2.get_ylim()[1])\n",
      "        ax2.set_xlabel('Radial dist. (arcsec.)')\n",
      "        ax2.set_ylabel('Est. counts ~ intensity')\n",
      "        \n",
      "    #############################\n",
      "    # Plot FWHM energy dependence\n",
      "    #############################\n",
      "\n",
      "    plt.figure(figsize=(8,6))\n",
      "    \n",
      "    for lab, m in zip(labels, xrange(len(labels))):\n",
      "        fwhm, fwhmc, fwhms = reg[lab]['meas']['fwhm'], reg[lab]['meas']['fwhmc'], reg[lab]['meas']['fwhms']\n",
      "        fwhm_fitc = reg[lab]['meas']['fwhm_fitc']\n",
      "        \n",
      "        # Plot FWHMs calculated from different methods, if possible\n",
      "        if np.isfinite(fwhm):\n",
      "            nerr, perr = reg[lab]['meas']['fwhm-errs']\n",
      "            plt.errorbar([m+1], [fwhm], yerr=[[nerr], [perr]], fmt='bs', label='2exp')\n",
      "        if np.isfinite(fwhmc):\n",
      "            nerr, perr = reg[lab]['meas']['fwhmc-errs']\n",
      "            plt.errorbar([m+1+0.03], [fwhmc], yerr=[[nerr], [perr]], fmt='go', mfc='none', label='2exp capped fwhm')\n",
      "        if np.isfinite(fwhms):\n",
      "            plt.plot([m+1+0.06], fwhms, 'rv', label='spline')  # Spline\n",
      "        if np.isfinite(fwhm_fitc):\n",
      "            nerr, perr = reg[lab]['meas']['fwhm_fitc-errs']\n",
      "            plt.errorbar([m+1-0.03], [fwhm_fitc], yerr=[[nerr], [perr]], fmt='b^', mfc='none', label='2exp capped fit')\n",
      "\n",
      "    plt.legend(loc='best')  # Legend not always correct\n",
      "    plt.xlim([0,len(labels)+1])\n",
      "    plt.xlabel('Energy band number')\n",
      "    plt.ylabel('FWHM (arcsec.)')\n",
      "    plt.show()\n",
      "    \n",
      "    ################################################\n",
      "    # Select which data you want to use in subsequent analysis...\n",
      "    # TEMPORARY -- using capped FWHM (2014 Sept. 14)\n",
      "    ################################################\n",
      "    for lab in labels:\n",
      "        \n",
      "        reg[lab]['meas']['fwhm'] = reg[lab]['meas']['fwhmc']\n",
      "        reg[lab]['meas']['fwhm-lims'] = reg[lab]['meas']['fwhmc-lims']\n",
      "        reg[lab]['meas']['fwhm-errs'] = reg[lab]['meas']['fwhmc-errs']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.3 CONFIGURATION CELL. Execute main methods (perform fits, make plots, save data)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This cell does all the legwork.  Read in the data and supporting information, then save useful information to a region dictionary...\n",
      "\n",
      "This is, essentially, a configuration cell.  Maybe save this to output as well -- list the configuration parameters used to generate/fit FWHMs.  At best, include versions for Python/Numpy/Scipy too."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# CHANGE VARIOUS SETTINGS HERE\n",
      "\n",
      "physreg = '../data-kepler/regions-1/regions-1.physreg'\n",
      "inroot = '../data-kepler/regions-1/profiles/prf'\n",
      "ctroot = '../data-kepler/regions-1/profiles/prf-cts'\n",
      "outroot = '../data-kepler/regions-1/fwhms/fwhms'\n",
      "\n",
      "labels = ['0.7-1kev', '1-2kev', '2-7kev']\n",
      "\n",
      "blacklist = {1:['0.7-1kev'],\n",
      "             2:['0.7-1kev'],\n",
      "             7:['0.7-1kev'],\n",
      "             8:['0.7-1kev'],\n",
      "             10:['0.7-1kev'],\n",
      "             11:['0.7-1kev'],\n",
      "             12:['0.7-1kev', '1-2kev'],\n",
      "             13:['0.7-1kev', '1-2kev'],\n",
      "             14:['0.7-1kev'],\n",
      "             15:['0.7-1kev'],\n",
      "             16:['0.7-1kev'],\n",
      "             17:['0.7-1kev', '1-2kev'],\n",
      "             18:['0.7-1kev'],\n",
      "             19:['0.7-1kev', '1-2kev'],\n",
      "             20:['0.7-1kev'],\n",
      "             21:['0.7-1kev', '1-2kev'],\n",
      "             22:['0.7-1kev']}\n",
      "\n",
      "px2arcsec = 0.492  # Chandra spatial resolution, http://cxc.harvard.edu/proposer/POG/html/chap6.html\n",
      "wlen = 13\n",
      "wtype = 'hanning'\n",
      "dx = 2\n",
      "xconst = 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.4 Start running computations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First load the region dictionary and apply cuts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "regions = init_region_dict(physreg, inroot, ctroot, labels, px2arcsec)\n",
      "regions = add_cut_data(regions, wlen, wtype)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that plots look okay.  Go up and revise the blacklist as needed"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for n in regions:\n",
      "    reg = regions[n]\n",
      "    print 'Region {}'.format(n)\n",
      "    plt.figure(figsize=(12,5))\n",
      "    for lab in reg:\n",
      "        if lab == 'info':\n",
      "            continue\n",
      "        \n",
      "        if '0.7-1' in lab:\n",
      "            c, i = 'r', 1\n",
      "        elif '1-2' in lab:\n",
      "            c, i = 'g', 2\n",
      "        else:\n",
      "            c, i = 'b', 3\n",
      "        plt.subplot(1,3,i)\n",
      "        \n",
      "        x, y, y_err = reg[lab]['data']\n",
      "        x_fit, y_fit, y_err_fit = reg[lab]['data-fit']\n",
      "        \n",
      "        plt.errorbar(x, y, yerr=y_err, fmt='rx', alpha=0.2)  # All raw data\n",
      "        plt.errorbar(x_fit, y_fit, yerr=y_err_fit, fmt='bo', alpha=0.4)  # Show data used in fit\n",
      "        plt.plot(x, fsmth.std_smooth(y, wlen, wtype), '.-k', alpha = 1)  # Show smoothing to set fit domain\n",
      "        \n",
      "        cut = fsmth.ind_first_min(y, window_len=wlen, window=wtype)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that FHWMs look okay.  Check that your cut locations for spectra are all valid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for n in regions:\n",
      "    print 'Region {:02d}'.format(n)\n",
      "    print '========='\n",
      "    \n",
      "    blist = [] if n not in blacklist else blacklist[n]\n",
      "    print 'Blacklisting energy bands: {}'.format(blist)\n",
      "    fill_region_dict(regions[n], wlen, wtype, dx, xconst, blist)  # Called by itself, will modify the dict entries"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove blacklisted FWHM measurements\n",
      "for n in blacklist:\n",
      "    for lab in blacklist[n]:\n",
      "        meas = regions[n][lab]['meas']\n",
      "        meas['fwhm'] = float('NaN')\n",
      "        meas['fwhm-errs'] = (float('NaN'), float('NaN'))\n",
      "        meas['fwhm-lims'] = (float('NaN'), float('NaN'))\n",
      "\n",
      "# Add cut locations for spectra (must do this AFTER blacklisting)\n",
      "def get_cuts(reg):\n",
      "    \"\"\"Cut locations for spectra in arcsec, parsed from region dictionary\n",
      "    Ignores any profile bands where FWHM could not be found\n",
      "    \"\"\"\n",
      "    x_btw = np.nanmin([reg[lab]['meas']['fwhm-lims'][0] for lab in labels])\n",
      "    x_max = np.nanmax([reg[lab]['meas']['fwhm-lims'][1] for lab in labels])\n",
      "    \n",
      "    x_min = -1\n",
      "    for lab in labels:\n",
      "        # Only use cuts where FWHM could be fitted\n",
      "        if np.isfinite(reg[lab]['meas']['fwhm']):\n",
      "            ind = reg[lab]['cut']\n",
      "            x_cut = reg[lab]['data'][0][ind]\n",
      "            if x_min > x_cut or x_min == -1:\n",
      "                x_min = x_cut\n",
      "    if x_min == -1:\n",
      "        print 'WARNING: could not find fit domain minimum?!'\n",
      "        x_min = 0\n",
      "    \n",
      "    return x_min, x_btw, x_max\n",
      "\n",
      "for n in regions.keys():\n",
      "    print 'Region {}'.format(n)\n",
      "    x_min, x_btw, x_max = get_cuts(regions[n])\n",
      "    regions[n]['info']['spec_cuts'] = x_min, x_btw, x_max\n",
      "    print 'Cut spectra at:', x_min, x_btw, x_max\n",
      "    assert x_min <= x_btw\n",
      "    assert x_btw <= x_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3.4 Export data to pickle (Python serialization) and plaintext"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For each region and energy band, we have now packaged lots of data.  Raw data (`data`, `data-fit`) are stored as `x`, `y`, and `y` errors.  Full width half maxes are stored with their left/right bounds; their errors (neg, pos) have separate keys."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print regions.keys()\n",
      "print regions[1].keys()\n",
      "print '\\t',regions[1]['info'].keys()\n",
      "print regions[1]['0.7-1kev'].keys()\n",
      "print regions[1]['0.7-1kev']['meas'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "FOR NOW, in LIEU OF GOOD CODE -- make the fwhms directory (specified by outroot) first, before dumping to pkl etc."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Currently dumping information to a Python pickle, plaintext (with much less information), and a config log.\n",
      "\n",
      "The pickle file is NOT interoperable (compare JSON, which may be better for archival purposes), but in principle we should be able to reproduce all numbers from Python anyways.  See [http://stackoverflow.com/q/2259270](http://stackoverflow.com/q/2259270).\n",
      "\n",
      "N.b., to use JSON, you need a Numpy aware encoder (see [http://stackoverflow.com/q/3488934](http://stackoverflow.com/q/3488934)).\n",
      "\n",
      "As it stands, the source code of the function in our region dict should be run using Python's `exec`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "with open('{}.pkl'.format(outroot), 'w') as fobj:\n",
      "    pickle.dump(regions, fobj)\n",
      "\n",
      "with open('{}.txt'.format(outroot), 'w') as fobj:\n",
      "    for n in regions.keys():\n",
      "        for lab in labels:\n",
      "            outstr = '{:d} {:.3f} {:.3f} {:.3f}'.format(n, regions[n][lab]['meas']['fwhm'],\n",
      "                                                        *regions[n][lab]['meas']['fwhm-errs'])\n",
      "            fobj.write(outstr+'\\n')\n",
      "\n",
      "with open('{}.log'.format(outroot), 'w') as fobj:\n",
      "    fobj.write('Config log (local/system time: {})\\n'.format(datetime.datetime.now()))\n",
      "    fobj.write('\\nInputs:\\n')\n",
      "    \n",
      "    # Keep this updated (dear lord this is terrible)\n",
      "    invars = ['physreg', 'inroot', 'ctroot', 'outroot', 'labels', 'px2arcsec', 'wlen', 'wtype']\n",
      "    for v in invars:\n",
      "        fobj.write('{} = {}\\n'.format(v, eval(v)))\n",
      "    \n",
      "    # Keep this updated\n",
      "    fobj.write('\\nOutputs:\\n')\n",
      "    fobj.write('{}.pkl (Python pickle/serialization)\\n'.format(outroot))\n",
      "    fobj.write('{}.txt (plaintext regions and FWHM measurements)\\n'.format(outroot))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}